{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T2T_ViT_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2e8131bcaf54d2a84e54fe2a257f687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6acdd2a0c134725a17b46bde8c26ab4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8e2e9cb89c54fe3a4959f66b77d577e",
              "IPY_MODEL_cdde3c55f70a4eae94a39a831eae8c4c"
            ]
          }
        },
        "d6acdd2a0c134725a17b46bde8c26ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8e2e9cb89c54fe3a4959f66b77d577e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b80047144b7b48b8a85b1a24a5ada8ff",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_184920ef4b5a4406bd4e72ff12556343"
          }
        },
        "cdde3c55f70a4eae94a39a831eae8c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df88f929ab8940db9142a77b36316868",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [02:15&lt;00:00, 13.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d084ec9697474a08945ccfca88290a71"
          }
        },
        "b80047144b7b48b8a85b1a24a5ada8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "184920ef4b5a4406bd4e72ff12556343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df88f929ab8940db9142a77b36316868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d084ec9697474a08945ccfca88290a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de6bd5bfc8ee433bb70af70b12f315d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_518d3e0948664423a6685671b64ad0a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f85fddf119448d8a4e305d28718eab5",
              "IPY_MODEL_04889eed0ea7469baac337705d5c5509"
            ]
          }
        },
        "518d3e0948664423a6685671b64ad0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f85fddf119448d8a4e305d28718eab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35747fc5e10f4cf29e0dbf9981568000",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b05632ecb294adb824a8d2ac8757f38"
          }
        },
        "04889eed0ea7469baac337705d5c5509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a316790a26f64dad80565666ccad2d02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [00:23&lt;00:00,  2.33s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e602ca774974ef2b5fbf3479a654804"
          }
        },
        "35747fc5e10f4cf29e0dbf9981568000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b05632ecb294adb824a8d2ac8757f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a316790a26f64dad80565666ccad2d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e602ca774974ef2b5fbf3479a654804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dde484c16e747fd97c7d0e369077a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6c31fb3df914c9c811a2cf15933d9dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5f9cb0cf641499cafd72b2f9d0b19d3",
              "IPY_MODEL_11035b9832da49c18c6732ac202aaf06"
            ]
          }
        },
        "a6c31fb3df914c9c811a2cf15933d9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5f9cb0cf641499cafd72b2f9d0b19d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_91a614bae6914a2b9a287a2f43823b70",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f48f01a82f4d4341886a3c7ca2ab8a3b"
          }
        },
        "11035b9832da49c18c6732ac202aaf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3d64cf24dab4003b41afc743da0578b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60000/60000 [01:07&lt;00:00, 891.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f62b0676ad94243a054e09907a31665"
          }
        },
        "91a614bae6914a2b9a287a2f43823b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f48f01a82f4d4341886a3c7ca2ab8a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3d64cf24dab4003b41afc743da0578b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f62b0676ad94243a054e09907a31665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swpi8IA7bhZm",
        "outputId": "08d9aaaa-2e59-41ae-ec12-34055af558b7"
      },
      "source": [
        "!git clone https://github.com/teavanist/MNIST-JPG"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MNIST-JPG'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 29 (delta 3), reused 2 (delta 0), pack-reused 20\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6t6delGbVvw"
      },
      "source": [
        "import os\r\n",
        "from glob import glob\r\n",
        "from subprocess import run\r\n",
        "\r\n",
        "for gz in glob(os.path.join('/content', '*.gz')):\r\n",
        "    after = gz.replace('-idx', '.idx')\r\n",
        "    os.rename(gz, after)\r\n",
        "    run(['gunzip', after])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9JLm9bfbi2-",
        "outputId": "34b8330e-a7d8-4597-baed-ddb3d98e5b0d"
      },
      "source": [
        "mnist_dir = '/content/data_mnist'\r\n",
        "os.makedirs(mnist_dir, exist_ok=True)\r\n",
        "\r\n",
        "!python /content/MNIST-JPG/mnist_jpg.py \"$mnist_dir\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writing /content/data_mnist/testing/5/9982.jpg\n",
            "writing /content/data_mnist/testing/0/9983.jpg\n",
            "writing /content/data_mnist/testing/1/9984.jpg\n",
            "writing /content/data_mnist/testing/2/9985.jpg\n",
            "writing /content/data_mnist/testing/3/9986.jpg\n",
            "writing /content/data_mnist/testing/4/9987.jpg\n",
            "writing /content/data_mnist/testing/5/9988.jpg\n",
            "writing /content/data_mnist/testing/6/9989.jpg\n",
            "writing /content/data_mnist/testing/7/9990.jpg\n",
            "writing /content/data_mnist/testing/8/9991.jpg\n",
            "writing /content/data_mnist/testing/9/9992.jpg\n",
            "writing /content/data_mnist/testing/0/9993.jpg\n",
            "writing /content/data_mnist/testing/1/9994.jpg\n",
            "writing /content/data_mnist/testing/2/9995.jpg\n",
            "writing /content/data_mnist/testing/3/9996.jpg\n",
            "writing /content/data_mnist/testing/4/9997.jpg\n",
            "writing /content/data_mnist/testing/5/9998.jpg\n",
            "writing /content/data_mnist/testing/6/9999.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "f2e8131bcaf54d2a84e54fe2a257f687",
            "d6acdd2a0c134725a17b46bde8c26ab4",
            "b8e2e9cb89c54fe3a4959f66b77d577e",
            "cdde3c55f70a4eae94a39a831eae8c4c",
            "b80047144b7b48b8a85b1a24a5ada8ff",
            "184920ef4b5a4406bd4e72ff12556343",
            "df88f929ab8940db9142a77b36316868",
            "d084ec9697474a08945ccfca88290a71",
            "de6bd5bfc8ee433bb70af70b12f315d0",
            "518d3e0948664423a6685671b64ad0a7",
            "9f85fddf119448d8a4e305d28718eab5",
            "04889eed0ea7469baac337705d5c5509",
            "35747fc5e10f4cf29e0dbf9981568000",
            "9b05632ecb294adb824a8d2ac8757f38",
            "a316790a26f64dad80565666ccad2d02",
            "8e602ca774974ef2b5fbf3479a654804"
          ]
        },
        "id": "rfJHNmdzbktd",
        "outputId": "6ca93ca2-3745-4547-b533-96895654cce0"
      },
      "source": [
        "from tqdm.auto import tqdm\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "for f in ['train', 'val']:\r\n",
        "    for i in range(10):\r\n",
        "        os.makedirs(f'/content/data/{f}/{i}', exist_ok=True)\r\n",
        "\r\n",
        "for f_in in ['training', 'testing']:\r\n",
        "    print(f'{f_in} folder')\r\n",
        "    for j in tqdm(range(10)):\r\n",
        "        dir = f'/content/data_mnist/{f_in}/{j}'\r\n",
        "        for image in os.listdir(dir):\r\n",
        "            path_in = os.path.join(dir, image)\r\n",
        "            I = Image.open(path_in).resize((224, 224)).convert('RGB')\r\n",
        "            if f_in == 'training':\r\n",
        "                f_out = 'train'\r\n",
        "            else:\r\n",
        "                f_out = 'val'\r\n",
        "            path_out = f'/content/data/{f_out}/{j}/{image}'\r\n",
        "            I.save(path_out)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training folder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e8131bcaf54d2a84e54fe2a257f687",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "testing folder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de6bd5bfc8ee433bb70af70b12f315d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "4dde484c16e747fd97c7d0e369077a2e",
            "a6c31fb3df914c9c811a2cf15933d9dc",
            "c5f9cb0cf641499cafd72b2f9d0b19d3",
            "11035b9832da49c18c6732ac202aaf06",
            "91a614bae6914a2b9a287a2f43823b70",
            "f48f01a82f4d4341886a3c7ca2ab8a3b",
            "f3d64cf24dab4003b41afc743da0578b",
            "1f62b0676ad94243a054e09907a31665"
          ]
        },
        "id": "rRT0KZcSbnhW",
        "outputId": "069c82fb-545f-484b-c2cd-5ba9b672fc99"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "path_images = Path('/content/data/train')\r\n",
        "num_images = len(list(path_images.glob('**/*.jpg')))\r\n",
        "mean = 0\r\n",
        "std = 0\r\n",
        "for image in tqdm(path_images.glob('**/*.jpg'), total=num_images):\r\n",
        "    image = str(image)\r\n",
        "    img = cv2.imread(image)\r\n",
        "    mean += np.mean(img[:, :, 0]) / num_images\r\n",
        "    std += np.std(img[:, :, 0]) / num_images\r\n",
        "mean, std"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dde484c16e747fd97c7d0e369077a2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34.51498935015433, 73.50595929282494)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6TzjRdbqF1",
        "outputId": "1c9bb4c1-33f5-40ac-ac65-6eb412cb02b8"
      },
      "source": [
        "!pip install timm\r\n",
        "!git clone https://github.com/yitu-opensource/T2T-ViT"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/ba02d533cec7329323c7d7a317ab49f673846ecef202d4cc40988b6b7786/timm-0.3.4-py3-none-any.whl (244kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 133kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 143kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 153kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 163kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 174kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 184kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 194kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 204kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 215kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 225kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.1+cu101)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.3.4\n",
            "Cloning into 'T2T-ViT'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 32 (delta 17), reused 15 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Br7-K6vbsWP",
        "outputId": "07031119-b758-4292-e10f-fdd4b311cc38"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/T2T-ViT')\r\n",
        "\r\n",
        "PATH_TO_DATA = '/content/data'\r\n",
        "\r\n",
        "!bash distributed_train.sh 1 \"$PATH_TO_DATA\"\\\r\n",
        "    --model T2t_vit_t_14\\\r\n",
        "    --batch-size 32\\\r\n",
        "    --num-classes 10\\\r\n",
        "    --img-size 224\\\r\n",
        "    --mean 34.515\\\r\n",
        "    --std 73.506\\\r\n",
        "    --lr 1e-4\\\r\n",
        "    --epochs 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with a single process on 1 GPUs.\n",
            "adopt transformer encoder for tokens-to-token\n",
            "Model T2t_vit_t_14 created, param count: 21159920\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 224, 224)\n",
            "\tinterpolation: bicubic\n",
            "\tmean: (34.515, 34.515, 34.515)\n",
            "\tstd: (73.506, 73.506, 73.506)\n",
            "\tcrop_pct: 0.9\n",
            "Using native Torch AMP. Training in mixed precision.\n",
            "Scheduled epochs: 11\n",
            "Train: 0 [   0/1875 (  0%)]  Loss:  2.332949 (2.3329)  Time: 2.328s,   13.75/s  (2.328s,   13.75/s)  LR: 1.000e-06  Data: 1.470 (1.470)\n",
            "Train: 0 [  50/1875 (  3%)]  Loss:  2.300109 (2.3300)  Time: 0.430s,   74.46/s  (0.468s,   68.33/s)  LR: 1.000e-06  Data: 0.004 (0.033)\n",
            "Train: 0 [ 100/1875 (  5%)]  Loss:  2.323153 (2.3328)  Time: 0.429s,   74.59/s  (0.449s,   71.22/s)  LR: 1.000e-06  Data: 0.004 (0.019)\n",
            "Train: 0 [ 150/1875 (  8%)]  Loss:  2.383229 (2.3309)  Time: 0.426s,   75.13/s  (0.443s,   72.27/s)  LR: 1.000e-06  Data: 0.004 (0.014)\n",
            "Train: 0 [ 200/1875 ( 11%)]  Loss:  2.309027 (2.3269)  Time: 0.429s,   74.57/s  (0.440s,   72.80/s)  LR: 1.000e-06  Data: 0.004 (0.011)\n",
            "Train: 0 [ 250/1875 ( 13%)]  Loss:  2.293190 (2.3253)  Time: 0.427s,   74.86/s  (0.438s,   73.14/s)  LR: 1.000e-06  Data: 0.004 (0.010)\n",
            "Train: 0 [ 300/1875 ( 16%)]  Loss:  2.348891 (2.3255)  Time: 0.429s,   74.51/s  (0.436s,   73.37/s)  LR: 1.000e-06  Data: 0.004 (0.009)\n",
            "Train: 0 [ 350/1875 ( 19%)]  Loss:  2.310586 (2.3242)  Time: 0.430s,   74.46/s  (0.435s,   73.51/s)  LR: 1.000e-06  Data: 0.004 (0.008)\n",
            "Train: 0 [ 400/1875 ( 21%)]  Loss:  2.346153 (2.3233)  Time: 0.427s,   74.86/s  (0.435s,   73.63/s)  LR: 1.000e-06  Data: 0.004 (0.008)\n",
            "Train: 0 [ 450/1875 ( 24%)]  Loss:  2.344241 (2.3222)  Time: 0.430s,   74.34/s  (0.434s,   73.71/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 500/1875 ( 27%)]  Loss:  2.308377 (2.3215)  Time: 0.432s,   74.07/s  (0.434s,   73.76/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 550/1875 ( 29%)]  Loss:  2.297870 (2.3206)  Time: 0.429s,   74.57/s  (0.433s,   73.82/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 600/1875 ( 32%)]  Loss:  2.279943 (2.3198)  Time: 0.430s,   74.36/s  (0.433s,   73.86/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 650/1875 ( 35%)]  Loss:  2.349958 (2.3185)  Time: 0.430s,   74.46/s  (0.433s,   73.90/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 700/1875 ( 37%)]  Loss:  2.294075 (2.3176)  Time: 0.430s,   74.42/s  (0.433s,   73.93/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 750/1875 ( 40%)]  Loss:  2.314196 (2.3171)  Time: 0.429s,   74.62/s  (0.433s,   73.95/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 800/1875 ( 43%)]  Loss:  2.308202 (2.3173)  Time: 0.428s,   74.77/s  (0.433s,   73.98/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 850/1875 ( 45%)]  Loss:  2.296963 (2.3166)  Time: 0.430s,   74.39/s  (0.432s,   74.01/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 900/1875 ( 48%)]  Loss:  2.326334 (2.3164)  Time: 0.430s,   74.46/s  (0.432s,   74.03/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 950/1875 ( 51%)]  Loss:  2.360874 (2.3162)  Time: 0.428s,   74.71/s  (0.432s,   74.05/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1000/1875 ( 53%)]  Loss:  2.341107 (2.3156)  Time: 0.429s,   74.63/s  (0.432s,   74.07/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1050/1875 ( 56%)]  Loss:  2.279023 (2.3153)  Time: 0.429s,   74.58/s  (0.432s,   74.09/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1100/1875 ( 59%)]  Loss:  2.259860 (2.3149)  Time: 0.427s,   74.87/s  (0.432s,   74.10/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1150/1875 ( 61%)]  Loss:  2.307663 (2.3144)  Time: 0.430s,   74.39/s  (0.432s,   74.11/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1200/1875 ( 64%)]  Loss:  2.273657 (2.3137)  Time: 0.430s,   74.38/s  (0.432s,   74.12/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1250/1875 ( 67%)]  Loss:  2.314316 (2.3132)  Time: 0.431s,   74.30/s  (0.432s,   74.13/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1300/1875 ( 69%)]  Loss:  2.357006 (2.3127)  Time: 0.431s,   74.21/s  (0.432s,   74.14/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1350/1875 ( 72%)]  Loss:  2.301502 (2.3120)  Time: 0.431s,   74.26/s  (0.432s,   74.15/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1400/1875 ( 75%)]  Loss:  2.271030 (2.3113)  Time: 0.432s,   74.15/s  (0.432s,   74.16/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1450/1875 ( 77%)]  Loss:  2.277631 (2.3106)  Time: 0.428s,   74.75/s  (0.431s,   74.16/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1500/1875 ( 80%)]  Loss:  2.308633 (2.3098)  Time: 0.429s,   74.55/s  (0.431s,   74.17/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1550/1875 ( 83%)]  Loss:  2.293630 (2.3095)  Time: 0.429s,   74.62/s  (0.431s,   74.18/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1600/1875 ( 85%)]  Loss:  2.294892 (2.3091)  Time: 0.427s,   74.91/s  (0.431s,   74.18/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1650/1875 ( 88%)]  Loss:  2.298492 (2.3088)  Time: 0.430s,   74.36/s  (0.431s,   74.19/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1700/1875 ( 91%)]  Loss:  2.295174 (2.3084)  Time: 0.431s,   74.27/s  (0.431s,   74.19/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1750/1875 ( 93%)]  Loss:  2.316978 (2.3080)  Time: 0.428s,   74.81/s  (0.431s,   74.20/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1800/1875 ( 96%)]  Loss:  2.267679 (2.3074)  Time: 0.429s,   74.56/s  (0.431s,   74.20/s)  LR: 1.000e-06  Data: 0.005 (0.005)\n",
            "Train: 0 [1850/1875 ( 99%)]  Loss:  2.336160 (2.3073)  Time: 0.430s,   74.50/s  (0.431s,   74.21/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1874/1875 (100%)]  Loss:  2.306372 (2.3071)  Time: 0.564s,   56.69/s  (0.431s,   74.20/s)  LR: 1.000e-06  Data: 0.142 (0.005)\n",
            "Test: [   0/312]  Time: 1.253 (1.253)  Loss:  2.2910 (2.2910)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 43.7500 (43.7500)\n",
            "Test: [  50/312]  Time: 0.147 (0.161)  Loss:  1.8330 (2.0799)  Acc@1: 96.8750 (39.7672)  Acc@5: 100.0000 (70.7108)\n",
            "Test: [ 100/312]  Time: 0.139 (0.149)  Loss:  2.2773 (2.1225)  Acc@1: 15.6250 (34.7772)  Acc@5: 65.6250 (53.9604)\n",
            "Test: [ 150/312]  Time: 0.137 (0.144)  Loss:  2.2676 (2.1704)  Acc@1:  0.0000 (25.2070)  Acc@5: 84.3750 (63.1416)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  2.2129 (2.2239)  Acc@1:  9.3750 (19.5585)  Acc@5: 100.0000 (58.0224)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  2.2129 (2.2140)  Acc@1: 43.7500 (25.3984)  Acc@5: 87.5000 (66.2849)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  2.2949 (2.2264)  Acc@1:  0.0000 (21.1794)  Acc@5: 46.8750 (66.1545)\n",
            "Test: [ 312/312]  Time: 0.207 (0.139)  Loss:  2.2949 (2.2288)  Acc@1:  0.0000 (20.4000)  Acc@5: 62.5000 (66.2700)\n",
            "Test (EMA): [   0/312]  Time: 1.180 (1.180)  Loss:  1.9658 (1.9658)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.139 (0.160)  Loss:  1.9941 (1.9774)  Acc@1:  3.1250 (60.7230)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  2.6406 (2.0983)  Acc@1:  0.0000 (30.6621)  Acc@5:  0.0000 (65.4394)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.143)  Loss:  2.2148 (2.2183)  Acc@1:  0.0000 (20.5091)  Acc@5: 100.0000 (57.7401)\n",
            "Test (EMA): [ 200/312]  Time: 0.141 (0.141)  Loss:  2.4375 (2.2359)  Acc@1:  0.0000 (15.4073)  Acc@5:  0.0000 (62.0180)\n",
            "Test (EMA): [ 250/312]  Time: 0.138 (0.140)  Loss:  2.6484 (2.3069)  Acc@1:  0.0000 (12.3381)  Acc@5:  0.0000 (49.6638)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.2246 (2.3322)  Acc@1:  0.0000 (10.2886)  Acc@5: 100.0000 (48.0689)\n",
            "Test (EMA): [ 312/312]  Time: 0.209 (0.139)  Loss:  2.2246 (2.3283)  Acc@1:  0.0000 ( 9.9100)  Acc@5: 100.0000 (49.9800)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            "\n",
            "Train: 1 [   0/1875 (  0%)]  Loss:  2.323737 (2.3237)  Time: 2.276s,   14.06/s  (2.276s,   14.06/s)  LR: 3.400e-05  Data: 1.302 (1.302)\n",
            "Train: 1 [  50/1875 (  3%)]  Loss:  2.349925 (2.3279)  Time: 0.429s,   74.58/s  (0.467s,   68.46/s)  LR: 3.400e-05  Data: 0.004 (0.031)\n",
            "Train: 1 [ 100/1875 (  5%)]  Loss:  2.330128 (2.3170)  Time: 0.429s,   74.62/s  (0.448s,   71.38/s)  LR: 3.400e-05  Data: 0.004 (0.017)\n",
            "Train: 1 [ 150/1875 (  8%)]  Loss:  2.394585 (2.3150)  Time: 0.438s,   73.09/s  (0.442s,   72.36/s)  LR: 3.400e-05  Data: 0.009 (0.013)\n",
            "Train: 1 [ 200/1875 ( 11%)]  Loss:  2.306908 (2.3129)  Time: 0.430s,   74.45/s  (0.439s,   72.88/s)  LR: 3.400e-05  Data: 0.004 (0.011)\n",
            "Train: 1 [ 250/1875 ( 13%)]  Loss:  2.333687 (2.3096)  Time: 0.432s,   74.11/s  (0.437s,   73.15/s)  LR: 3.400e-05  Data: 0.004 (0.009)\n",
            "Train: 1 [ 300/1875 ( 16%)]  Loss:  2.218466 (2.3052)  Time: 0.429s,   74.67/s  (0.436s,   73.35/s)  LR: 3.400e-05  Data: 0.004 (0.009)\n",
            "Train: 1 [ 350/1875 ( 19%)]  Loss:  2.304269 (2.3024)  Time: 0.449s,   71.34/s  (0.436s,   73.47/s)  LR: 3.400e-05  Data: 0.004 (0.008)\n",
            "Train: 1 [ 400/1875 ( 21%)]  Loss:  2.187855 (2.3002)  Time: 0.429s,   74.61/s  (0.435s,   73.57/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 450/1875 ( 24%)]  Loss:  2.184251 (2.2976)  Time: 0.437s,   73.16/s  (0.434s,   73.67/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 500/1875 ( 27%)]  Loss:  2.253967 (2.2949)  Time: 0.432s,   74.08/s  (0.434s,   73.75/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 550/1875 ( 29%)]  Loss:  2.274897 (2.2936)  Time: 0.432s,   74.09/s  (0.434s,   73.81/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 600/1875 ( 32%)]  Loss:  2.295680 (2.2920)  Time: 0.431s,   74.29/s  (0.433s,   73.85/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 650/1875 ( 35%)]  Loss:  2.220811 (2.2898)  Time: 0.428s,   74.85/s  (0.433s,   73.90/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 700/1875 ( 37%)]  Loss:  2.258009 (2.2861)  Time: 0.428s,   74.71/s  (0.433s,   73.93/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 750/1875 ( 40%)]  Loss:  2.172801 (2.2849)  Time: 0.429s,   74.52/s  (0.433s,   73.96/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 800/1875 ( 43%)]  Loss:  2.158181 (2.2833)  Time: 0.432s,   74.08/s  (0.433s,   73.98/s)  LR: 3.400e-05  Data: 0.005 (0.006)\n",
            "Train: 1 [ 850/1875 ( 45%)]  Loss:  2.262387 (2.2804)  Time: 0.428s,   74.71/s  (0.432s,   74.01/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 900/1875 ( 48%)]  Loss:  2.285605 (2.2790)  Time: 0.429s,   74.59/s  (0.432s,   74.03/s)  LR: 3.400e-05  Data: 0.005 (0.006)\n",
            "Train: 1 [ 950/1875 ( 51%)]  Loss:  2.245830 (2.2765)  Time: 0.430s,   74.47/s  (0.432s,   74.05/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1000/1875 ( 53%)]  Loss:  2.242745 (2.2718)  Time: 0.429s,   74.58/s  (0.432s,   74.06/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1050/1875 ( 56%)]  Loss:  2.178483 (2.2671)  Time: 0.429s,   74.68/s  (0.432s,   74.07/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1100/1875 ( 59%)]  Loss:  1.951619 (2.2618)  Time: 0.436s,   73.37/s  (0.432s,   74.09/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1150/1875 ( 61%)]  Loss:  1.962297 (2.2573)  Time: 0.428s,   74.82/s  (0.432s,   74.11/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1200/1875 ( 64%)]  Loss:  2.142655 (2.2540)  Time: 0.427s,   74.87/s  (0.432s,   74.13/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1250/1875 ( 67%)]  Loss:  1.917770 (2.2491)  Time: 0.429s,   74.67/s  (0.432s,   74.16/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1300/1875 ( 69%)]  Loss:  2.269610 (2.2463)  Time: 0.429s,   74.51/s  (0.431s,   74.17/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1350/1875 ( 72%)]  Loss:  2.021808 (2.2418)  Time: 0.431s,   74.21/s  (0.431s,   74.18/s)  LR: 3.400e-05  Data: 0.005 (0.005)\n",
            "Train: 1 [1400/1875 ( 75%)]  Loss:  2.192350 (2.2376)  Time: 0.430s,   74.34/s  (0.431s,   74.18/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1450/1875 ( 77%)]  Loss:  2.200607 (2.2354)  Time: 0.429s,   74.66/s  (0.431s,   74.19/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1500/1875 ( 80%)]  Loss:  2.002898 (2.2292)  Time: 0.429s,   74.53/s  (0.431s,   74.20/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1550/1875 ( 83%)]  Loss:  2.154931 (2.2250)  Time: 0.428s,   74.70/s  (0.431s,   74.20/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1600/1875 ( 85%)]  Loss:  2.194962 (2.2217)  Time: 0.430s,   74.50/s  (0.431s,   74.21/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1650/1875 ( 88%)]  Loss:  2.096284 (2.2178)  Time: 0.429s,   74.61/s  (0.431s,   74.21/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1700/1875 ( 91%)]  Loss:  2.109841 (2.2126)  Time: 0.430s,   74.35/s  (0.431s,   74.21/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1750/1875 ( 93%)]  Loss:  2.248212 (2.2100)  Time: 0.428s,   74.84/s  (0.431s,   74.22/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1800/1875 ( 96%)]  Loss:  2.397898 (2.2068)  Time: 0.439s,   72.91/s  (0.431s,   74.22/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1850/1875 ( 99%)]  Loss:  1.993858 (2.2015)  Time: 0.430s,   74.33/s  (0.431s,   74.22/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1874/1875 (100%)]  Loss:  2.027008 (2.1990)  Time: 0.570s,   56.14/s  (0.431s,   74.21/s)  LR: 3.400e-05  Data: 0.150 (0.005)\n",
            "Test: [   0/312]  Time: 1.160 (1.160)  Loss:  0.9243 (0.9243)  Acc@1: 90.6250 (90.6250)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [  50/312]  Time: 0.132 (0.159)  Loss:  0.3250 (0.7893)  Acc@1: 96.8750 (90.6863)  Acc@5: 100.0000 (98.9583)\n",
            "Test: [ 100/312]  Time: 0.140 (0.147)  Loss:  1.6631 (0.9611)  Acc@1: 25.0000 (83.6015)  Acc@5: 93.7500 (99.1646)\n",
            "Test: [ 150/312]  Time: 0.131 (0.143)  Loss:  0.6016 (1.0216)  Acc@1: 96.8750 (74.0894)  Acc@5: 100.0000 (99.0687)\n",
            "Test: [ 200/312]  Time: 0.131 (0.141)  Loss:  1.2891 (1.0585)  Acc@1: 68.7500 (75.6530)  Acc@5: 96.8750 (98.7562)\n",
            "Test: [ 250/312]  Time: 0.138 (0.140)  Loss:  0.8037 (0.9891)  Acc@1: 84.3750 (78.6230)  Acc@5: 100.0000 (98.9542)\n",
            "Test: [ 300/312]  Time: 0.130 (0.139)  Loss:  1.6807 (1.0262)  Acc@1: 53.1250 (77.7305)  Acc@5: 68.7500 (98.7853)\n",
            "Test: [ 312/312]  Time: 0.210 (0.139)  Loss:  0.8081 (1.0208)  Acc@1: 87.5000 (77.9300)  Acc@5: 100.0000 (98.8300)\n",
            "Test (EMA): [   0/312]  Time: 1.189 (1.189)  Loss:  1.9531 (1.9531)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.137 (0.160)  Loss:  2.1426 (2.0249)  Acc@1:  0.0000 (60.0490)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.137 (0.148)  Loss:  2.5195 (2.1177)  Acc@1:  0.0000 (30.3218)  Acc@5:  0.0000 (97.3700)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.144)  Loss:  2.2188 (2.2085)  Acc@1:  0.0000 (20.2815)  Acc@5: 100.0000 (79.0977)\n",
            "Test (EMA): [ 200/312]  Time: 0.146 (0.142)  Loss:  2.4121 (2.2335)  Acc@1:  0.0000 (15.2363)  Acc@5:  0.0000 (64.1947)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.141)  Loss:  2.5391 (2.2897)  Acc@1:  0.0000 (12.2012)  Acc@5:  0.0000 (51.4069)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  2.2500 (2.3078)  Acc@1:  0.0000 (10.1744)  Acc@5: 100.0000 (49.5224)\n",
            "Test (EMA): [ 312/312]  Time: 0.213 (0.140)  Loss:  2.2500 (2.3057)  Acc@1:  0.0000 ( 9.8000)  Acc@5: 100.0000 (51.3800)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 2 [   0/1875 (  0%)]  Loss:  1.885798 (1.8858)  Time: 2.299s,   13.92/s  (2.299s,   13.92/s)  LR: 6.700e-05  Data: 1.321 (1.321)\n",
            "Train: 2 [  50/1875 (  3%)]  Loss:  2.205975 (2.1194)  Time: 0.429s,   74.57/s  (0.469s,   68.21/s)  LR: 6.700e-05  Data: 0.004 (0.031)\n",
            "Train: 2 [ 100/1875 (  5%)]  Loss:  2.198737 (2.0590)  Time: 0.428s,   74.71/s  (0.450s,   71.07/s)  LR: 6.700e-05  Data: 0.004 (0.017)\n",
            "Train: 2 [ 150/1875 (  8%)]  Loss:  2.053829 (2.0513)  Time: 0.430s,   74.37/s  (0.444s,   72.09/s)  LR: 6.700e-05  Data: 0.004 (0.013)\n",
            "Train: 2 [ 200/1875 ( 11%)]  Loss:  2.096897 (2.0613)  Time: 0.434s,   73.69/s  (0.441s,   72.62/s)  LR: 6.700e-05  Data: 0.004 (0.011)\n",
            "Train: 2 [ 250/1875 ( 13%)]  Loss:  1.837934 (2.0659)  Time: 0.429s,   74.57/s  (0.439s,   72.96/s)  LR: 6.700e-05  Data: 0.004 (0.009)\n",
            "Train: 2 [ 300/1875 ( 16%)]  Loss:  1.791455 (2.0716)  Time: 0.429s,   74.52/s  (0.437s,   73.18/s)  LR: 6.700e-05  Data: 0.004 (0.009)\n",
            "Train: 2 [ 350/1875 ( 19%)]  Loss:  2.102025 (2.0599)  Time: 0.433s,   73.84/s  (0.436s,   73.34/s)  LR: 6.700e-05  Data: 0.004 (0.008)\n",
            "Train: 2 [ 400/1875 ( 21%)]  Loss:  2.214979 (2.0498)  Time: 0.430s,   74.48/s  (0.436s,   73.46/s)  LR: 6.700e-05  Data: 0.004 (0.008)\n",
            "Train: 2 [ 450/1875 ( 24%)]  Loss:  1.781810 (2.0444)  Time: 0.431s,   74.16/s  (0.435s,   73.54/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 500/1875 ( 27%)]  Loss:  1.833679 (2.0400)  Time: 0.431s,   74.25/s  (0.435s,   73.61/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 550/1875 ( 29%)]  Loss:  2.207707 (2.0483)  Time: 0.434s,   73.67/s  (0.434s,   73.69/s)  LR: 6.700e-05  Data: 0.009 (0.007)\n",
            "Train: 2 [ 600/1875 ( 32%)]  Loss:  1.909034 (2.0535)  Time: 0.429s,   74.57/s  (0.434s,   73.75/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 650/1875 ( 35%)]  Loss:  1.690422 (2.0376)  Time: 0.429s,   74.62/s  (0.434s,   73.79/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 700/1875 ( 37%)]  Loss:  2.117192 (2.0285)  Time: 0.429s,   74.66/s  (0.433s,   73.83/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 750/1875 ( 40%)]  Loss:  1.750446 (2.0234)  Time: 0.429s,   74.61/s  (0.433s,   73.87/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 800/1875 ( 43%)]  Loss:  1.860065 (2.0269)  Time: 0.431s,   74.33/s  (0.433s,   73.90/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 850/1875 ( 45%)]  Loss:  2.153346 (2.0212)  Time: 0.432s,   74.08/s  (0.433s,   73.93/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 900/1875 ( 48%)]  Loss:  2.168961 (2.0253)  Time: 0.431s,   74.29/s  (0.433s,   73.95/s)  LR: 6.700e-05  Data: 0.005 (0.006)\n",
            "Train: 2 [ 950/1875 ( 51%)]  Loss:  2.051842 (2.0275)  Time: 0.428s,   74.83/s  (0.433s,   73.98/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1000/1875 ( 53%)]  Loss:  1.772346 (2.0204)  Time: 0.432s,   74.13/s  (0.432s,   74.00/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1050/1875 ( 56%)]  Loss:  1.682307 (2.0128)  Time: 0.430s,   74.39/s  (0.432s,   74.01/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1100/1875 ( 59%)]  Loss:  1.670352 (2.0061)  Time: 0.436s,   73.36/s  (0.432s,   74.03/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1150/1875 ( 61%)]  Loss:  1.769636 (2.0024)  Time: 0.429s,   74.66/s  (0.432s,   74.04/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1200/1875 ( 64%)]  Loss:  2.026304 (2.0011)  Time: 0.429s,   74.58/s  (0.432s,   74.05/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1250/1875 ( 67%)]  Loss:  1.664812 (1.9958)  Time: 0.431s,   74.22/s  (0.432s,   74.07/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1300/1875 ( 69%)]  Loss:  2.135393 (1.9966)  Time: 0.430s,   74.43/s  (0.432s,   74.08/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1350/1875 ( 72%)]  Loss:  2.253277 (1.9934)  Time: 0.434s,   73.74/s  (0.432s,   74.09/s)  LR: 6.700e-05  Data: 0.007 (0.005)\n",
            "Train: 2 [1400/1875 ( 75%)]  Loss:  2.119290 (1.9908)  Time: 0.437s,   73.25/s  (0.432s,   74.10/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1450/1875 ( 77%)]  Loss:  2.003253 (1.9910)  Time: 0.428s,   74.75/s  (0.432s,   74.10/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1500/1875 ( 80%)]  Loss:  1.478171 (1.9829)  Time: 0.431s,   74.28/s  (0.432s,   74.11/s)  LR: 6.700e-05  Data: 0.005 (0.005)\n",
            "Train: 2 [1550/1875 ( 83%)]  Loss:  1.728371 (1.9792)  Time: 0.430s,   74.43/s  (0.432s,   74.12/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1600/1875 ( 85%)]  Loss:  2.164268 (1.9784)  Time: 0.431s,   74.29/s  (0.432s,   74.13/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1650/1875 ( 88%)]  Loss:  2.312669 (1.9746)  Time: 0.429s,   74.62/s  (0.432s,   74.13/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1700/1875 ( 91%)]  Loss:  1.619780 (1.9700)  Time: 0.431s,   74.33/s  (0.432s,   74.14/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1750/1875 ( 93%)]  Loss:  2.145354 (1.9709)  Time: 0.431s,   74.22/s  (0.432s,   74.15/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1800/1875 ( 96%)]  Loss:  2.422313 (1.9703)  Time: 0.430s,   74.45/s  (0.432s,   74.15/s)  LR: 6.700e-05  Data: 0.005 (0.005)\n",
            "Train: 2 [1850/1875 ( 99%)]  Loss:  1.510353 (1.9665)  Time: 0.431s,   74.27/s  (0.432s,   74.15/s)  LR: 6.700e-05  Data: 0.006 (0.005)\n",
            "Train: 2 [1874/1875 (100%)]  Loss:  1.411551 (1.9639)  Time: 0.572s,   55.96/s  (0.432s,   74.15/s)  LR: 6.700e-05  Data: 0.148 (0.005)\n",
            "Test: [   0/312]  Time: 1.201 (1.201)  Loss:  0.6572 (0.6572)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.143 (0.162)  Loss:  0.3892 (0.5937)  Acc@1: 96.8750 (90.6250)  Acc@5: 100.0000 (98.8358)\n",
            "Test: [ 100/312]  Time: 0.142 (0.148)  Loss:  0.9985 (0.6308)  Acc@1: 62.5000 (89.3564)  Acc@5: 100.0000 (99.3193)\n",
            "Test: [ 150/312]  Time: 0.138 (0.144)  Loss:  0.1226 (0.6631)  Acc@1: 100.0000 (81.7467)  Acc@5: 100.0000 (99.4412)\n",
            "Test: [ 200/312]  Time: 0.139 (0.142)  Loss:  0.4924 (0.6453)  Acc@1: 90.6250 (84.1729)  Acc@5: 100.0000 (99.5180)\n",
            "Test: [ 250/312]  Time: 0.138 (0.141)  Loss:  0.3640 (0.5850)  Acc@1: 93.7500 (86.6160)  Acc@5: 100.0000 (99.6140)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.8398 (0.5762)  Acc@1: 71.8750 (86.9913)  Acc@5: 96.8750 (99.6159)\n",
            "Test: [ 312/312]  Time: 0.211 (0.140)  Loss:  0.3491 (0.5705)  Acc@1: 93.7500 (87.1500)  Acc@5: 100.0000 (99.6300)\n",
            "Test (EMA): [   0/312]  Time: 1.273 (1.273)  Loss:  1.8945 (1.8945)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.160)  Loss:  2.1465 (1.9872)  Acc@1:  0.0000 (60.7230)  Acc@5: 100.0000 (99.8162)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  2.5117 (2.0832)  Acc@1:  0.0000 (30.6621)  Acc@5:  0.0000 (97.2772)\n",
            "Test (EMA): [ 150/312]  Time: 0.142 (0.144)  Loss:  2.1719 (2.1770)  Acc@1:  0.0000 (20.5091)  Acc@5: 100.0000 (79.0356)\n",
            "Test (EMA): [ 200/312]  Time: 0.141 (0.142)  Loss:  2.4395 (2.2201)  Acc@1:  0.0000 (15.4073)  Acc@5:  0.0000 (69.8694)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.140)  Loss:  2.4551 (2.2607)  Acc@1:  0.0000 (12.3381)  Acc@5:  0.0000 (55.9512)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.3164 (2.2882)  Acc@1:  0.0000 (10.2886)  Acc@5: 100.0000 (53.3119)\n",
            "Test (EMA): [ 312/312]  Time: 0.205 (0.139)  Loss:  2.3184 (2.2893)  Acc@1:  0.0000 ( 9.9100)  Acc@5: 100.0000 (55.0300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 3 [   0/1875 (  0%)]  Loss:  1.768197 (1.7682)  Time: 2.312s,   13.84/s  (2.312s,   13.84/s)  LR: 1.000e-05  Data: 1.336 (1.336)\n",
            "Train: 3 [  50/1875 (  3%)]  Loss:  2.061318 (1.9487)  Time: 0.430s,   74.40/s  (0.469s,   68.17/s)  LR: 1.000e-05  Data: 0.004 (0.031)\n",
            "Train: 3 [ 100/1875 (  5%)]  Loss:  2.223920 (1.8593)  Time: 0.432s,   74.14/s  (0.451s,   71.03/s)  LR: 1.000e-05  Data: 0.004 (0.018)\n",
            "Train: 3 [ 150/1875 (  8%)]  Loss:  2.217352 (1.8504)  Time: 0.430s,   74.39/s  (0.444s,   72.06/s)  LR: 1.000e-05  Data: 0.004 (0.013)\n",
            "Train: 3 [ 200/1875 ( 11%)]  Loss:  1.760356 (1.8762)  Time: 0.427s,   74.93/s  (0.441s,   72.60/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 3 [ 250/1875 ( 13%)]  Loss:  1.335858 (1.8867)  Time: 0.429s,   74.64/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 3 [ 300/1875 ( 16%)]  Loss:  1.504929 (1.8887)  Time: 0.429s,   74.58/s  (0.437s,   73.23/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 3 [ 350/1875 ( 19%)]  Loss:  1.377178 (1.8723)  Time: 0.426s,   75.12/s  (0.436s,   73.42/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 3 [ 400/1875 ( 21%)]  Loss:  1.883555 (1.8552)  Time: 0.427s,   74.92/s  (0.435s,   73.57/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 450/1875 ( 24%)]  Loss:  1.447005 (1.8531)  Time: 0.438s,   73.02/s  (0.434s,   73.68/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 500/1875 ( 27%)]  Loss:  1.520403 (1.8515)  Time: 0.429s,   74.54/s  (0.434s,   73.74/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 550/1875 ( 29%)]  Loss:  2.127911 (1.8660)  Time: 0.430s,   74.38/s  (0.434s,   73.79/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 600/1875 ( 32%)]  Loss:  1.587978 (1.8772)  Time: 0.431s,   74.16/s  (0.434s,   73.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 650/1875 ( 35%)]  Loss:  1.572014 (1.8580)  Time: 0.431s,   74.22/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 700/1875 ( 37%)]  Loss:  2.149139 (1.8490)  Time: 0.441s,   72.62/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 750/1875 ( 40%)]  Loss:  1.238407 (1.8445)  Time: 0.433s,   73.86/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 3 [ 800/1875 ( 43%)]  Loss:  1.766123 (1.8546)  Time: 0.430s,   74.37/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 850/1875 ( 45%)]  Loss:  2.140784 (1.8518)  Time: 0.430s,   74.50/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 900/1875 ( 48%)]  Loss:  2.239478 (1.8570)  Time: 0.431s,   74.23/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 950/1875 ( 51%)]  Loss:  1.936234 (1.8632)  Time: 0.431s,   74.31/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1000/1875 ( 53%)]  Loss:  1.418423 (1.8553)  Time: 0.432s,   74.04/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1050/1875 ( 56%)]  Loss:  1.547703 (1.8494)  Time: 0.431s,   74.23/s  (0.433s,   73.98/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1100/1875 ( 59%)]  Loss:  1.486547 (1.8426)  Time: 0.430s,   74.35/s  (0.433s,   73.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1150/1875 ( 61%)]  Loss:  1.335801 (1.8378)  Time: 0.434s,   73.79/s  (0.432s,   73.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1200/1875 ( 64%)]  Loss:  1.892351 (1.8391)  Time: 0.438s,   73.12/s  (0.432s,   73.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1250/1875 ( 67%)]  Loss:  1.380250 (1.8348)  Time: 0.434s,   73.81/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1300/1875 ( 69%)]  Loss:  2.188109 (1.8376)  Time: 0.429s,   74.52/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1350/1875 ( 72%)]  Loss:  2.009016 (1.8346)  Time: 0.430s,   74.45/s  (0.432s,   74.01/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1400/1875 ( 75%)]  Loss:  1.857431 (1.8335)  Time: 0.430s,   74.48/s  (0.432s,   74.01/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1450/1875 ( 77%)]  Loss:  1.661300 (1.8356)  Time: 0.432s,   74.12/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 3 [1500/1875 ( 80%)]  Loss:  1.454326 (1.8281)  Time: 0.431s,   74.20/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1550/1875 ( 83%)]  Loss:  1.306845 (1.8257)  Time: 0.433s,   73.84/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1600/1875 ( 85%)]  Loss:  2.001368 (1.8268)  Time: 0.431s,   74.22/s  (0.432s,   74.03/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1650/1875 ( 88%)]  Loss:  1.998971 (1.8245)  Time: 0.431s,   74.18/s  (0.432s,   74.03/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1700/1875 ( 91%)]  Loss:  1.386789 (1.8211)  Time: 0.434s,   73.80/s  (0.432s,   74.03/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 3 [1750/1875 ( 93%)]  Loss:  2.175878 (1.8242)  Time: 0.433s,   73.94/s  (0.432s,   74.03/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1800/1875 ( 96%)]  Loss:  2.105787 (1.8257)  Time: 0.429s,   74.68/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1850/1875 ( 99%)]  Loss:  1.378627 (1.8219)  Time: 0.431s,   74.19/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1874/1875 (100%)]  Loss:  1.589067 (1.8200)  Time: 0.568s,   56.29/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.146 (0.005)\n",
            "Test: [   0/312]  Time: 1.174 (1.174)  Loss:  0.1917 (0.1917)  Acc@1: 96.8750 (96.8750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.139 (0.160)  Loss:  0.1169 (0.2066)  Acc@1: 100.0000 (97.7941)  Acc@5: 100.0000 (99.9387)\n",
            "Test: [ 100/312]  Time: 0.141 (0.148)  Loss:  0.6938 (0.2505)  Acc@1: 87.5000 (96.1943)  Acc@5: 100.0000 (99.8762)\n",
            "Test: [ 150/312]  Time: 0.138 (0.144)  Loss:  0.1182 (0.3351)  Acc@1: 100.0000 (93.6258)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/312]  Time: 0.140 (0.142)  Loss:  0.3223 (0.4000)  Acc@1: 93.7500 (90.4540)  Acc@5: 100.0000 (99.8445)\n",
            "Test: [ 250/312]  Time: 0.131 (0.140)  Loss:  0.2278 (0.3874)  Acc@1: 96.8750 (91.3098)  Acc@5: 100.0000 (99.8630)\n",
            "Test: [ 300/312]  Time: 0.130 (0.139)  Loss:  0.9102 (0.3773)  Acc@1: 71.8750 (91.8189)  Acc@5: 100.0000 (99.8443)\n",
            "Test: [ 312/312]  Time: 0.210 (0.139)  Loss:  0.1624 (0.3717)  Acc@1: 100.0000 (92.0200)  Acc@5: 100.0000 (99.8500)\n",
            "Test (EMA): [   0/312]  Time: 1.158 (1.158)  Loss:  1.8232 (1.8232)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.137 (0.160)  Loss:  2.1094 (1.9304)  Acc@1:  0.0000 (60.9069)  Acc@5: 100.0000 (99.8162)\n",
            "Test (EMA): [ 100/312]  Time: 0.138 (0.147)  Loss:  2.5371 (2.0422)  Acc@1:  0.0000 (30.7550)  Acc@5:  0.0000 (97.2772)\n",
            "Test (EMA): [ 150/312]  Time: 0.138 (0.143)  Loss:  2.1191 (2.1465)  Acc@1:  0.0000 (20.5712)  Acc@5: 100.0000 (79.0356)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.141)  Loss:  2.4727 (2.2058)  Acc@1:  0.0000 (15.4540)  Acc@5:  0.0000 (64.2102)\n",
            "Test (EMA): [ 250/312]  Time: 0.143 (0.140)  Loss:  2.4219 (2.2398)  Acc@1:  0.0000 (12.3755)  Acc@5: 53.1250 (64.1683)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.3438 (2.2761)  Acc@1:  0.0000 (10.3198)  Acc@5: 68.7500 (57.0287)\n",
            "Test (EMA): [ 312/312]  Time: 0.208 (0.139)  Loss:  2.3438 (2.2785)  Acc@1:  0.0000 ( 9.9400)  Acc@5: 50.0000 (56.8200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 4 [   0/1875 (  0%)]  Loss:  1.614368 (1.6144)  Time: 2.386s,   13.41/s  (2.386s,   13.41/s)  LR: 1.000e-05  Data: 1.505 (1.505)\n",
            "Train: 4 [  50/1875 (  3%)]  Loss:  2.112417 (1.9082)  Time: 0.431s,   74.25/s  (0.470s,   68.14/s)  LR: 1.000e-05  Data: 0.004 (0.034)\n",
            "Train: 4 [ 100/1875 (  5%)]  Loss:  2.110053 (1.8057)  Time: 0.431s,   74.16/s  (0.451s,   70.95/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 4 [ 150/1875 (  8%)]  Loss:  2.143710 (1.8015)  Time: 0.431s,   74.25/s  (0.444s,   72.00/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 4 [ 200/1875 ( 11%)]  Loss:  1.673857 (1.8283)  Time: 0.428s,   74.82/s  (0.441s,   72.60/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 4 [ 250/1875 ( 13%)]  Loss:  1.238496 (1.8401)  Time: 0.430s,   74.42/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 4 [ 300/1875 ( 16%)]  Loss:  1.247927 (1.8374)  Time: 0.439s,   72.93/s  (0.437s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 4 [ 350/1875 ( 19%)]  Loss:  1.465592 (1.8212)  Time: 0.428s,   74.73/s  (0.437s,   73.31/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 400/1875 ( 21%)]  Loss:  2.151647 (1.8082)  Time: 0.429s,   74.57/s  (0.436s,   73.42/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 450/1875 ( 24%)]  Loss:  1.422746 (1.8023)  Time: 0.429s,   74.65/s  (0.435s,   73.52/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 500/1875 ( 27%)]  Loss:  1.289184 (1.8023)  Time: 0.429s,   74.51/s  (0.435s,   73.58/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 550/1875 ( 29%)]  Loss:  2.247950 (1.8198)  Time: 0.432s,   74.05/s  (0.435s,   73.63/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 600/1875 ( 32%)]  Loss:  1.643085 (1.8313)  Time: 0.430s,   74.45/s  (0.434s,   73.68/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 650/1875 ( 35%)]  Loss:  1.441118 (1.8125)  Time: 0.429s,   74.56/s  (0.434s,   73.72/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 700/1875 ( 37%)]  Loss:  1.791837 (1.8024)  Time: 0.429s,   74.56/s  (0.434s,   73.75/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 750/1875 ( 40%)]  Loss:  1.324630 (1.7983)  Time: 0.431s,   74.19/s  (0.434s,   73.77/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 800/1875 ( 43%)]  Loss:  1.938181 (1.8102)  Time: 0.438s,   73.00/s  (0.434s,   73.79/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 850/1875 ( 45%)]  Loss:  2.052595 (1.8069)  Time: 0.430s,   74.42/s  (0.434s,   73.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 900/1875 ( 48%)]  Loss:  2.155930 (1.8129)  Time: 0.429s,   74.57/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 950/1875 ( 51%)]  Loss:  1.879194 (1.8185)  Time: 0.432s,   74.07/s  (0.433s,   73.86/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1000/1875 ( 53%)]  Loss:  1.364056 (1.8132)  Time: 0.435s,   73.62/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.007 (0.006)\n",
            "Train: 4 [1050/1875 ( 56%)]  Loss:  1.470924 (1.8053)  Time: 0.430s,   74.48/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1100/1875 ( 59%)]  Loss:  1.219260 (1.7994)  Time: 0.430s,   74.34/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1150/1875 ( 61%)]  Loss:  1.490546 (1.7954)  Time: 0.429s,   74.67/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1200/1875 ( 64%)]  Loss:  2.024592 (1.7956)  Time: 0.429s,   74.60/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1250/1875 ( 67%)]  Loss:  1.241596 (1.7905)  Time: 0.428s,   74.85/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1300/1875 ( 69%)]  Loss:  2.110579 (1.7932)  Time: 0.429s,   74.64/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1350/1875 ( 72%)]  Loss:  2.111074 (1.7905)  Time: 0.428s,   74.72/s  (0.433s,   73.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1400/1875 ( 75%)]  Loss:  1.923672 (1.7894)  Time: 0.429s,   74.51/s  (0.432s,   73.99/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1450/1875 ( 77%)]  Loss:  1.954995 (1.7918)  Time: 0.431s,   74.28/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1500/1875 ( 80%)]  Loss:  1.175000 (1.7857)  Time: 0.429s,   74.56/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1550/1875 ( 83%)]  Loss:  1.154156 (1.7833)  Time: 0.429s,   74.53/s  (0.432s,   74.01/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1600/1875 ( 85%)]  Loss:  2.057819 (1.7856)  Time: 0.432s,   74.07/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 4 [1650/1875 ( 88%)]  Loss:  2.199728 (1.7841)  Time: 0.430s,   74.37/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1700/1875 ( 91%)]  Loss:  1.423181 (1.7802)  Time: 0.430s,   74.41/s  (0.432s,   74.03/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1750/1875 ( 93%)]  Loss:  2.068571 (1.7829)  Time: 0.432s,   74.14/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1800/1875 ( 96%)]  Loss:  2.310601 (1.7844)  Time: 0.431s,   74.29/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1850/1875 ( 99%)]  Loss:  1.273525 (1.7807)  Time: 0.431s,   74.22/s  (0.432s,   74.05/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1874/1875 (100%)]  Loss:  1.483605 (1.7789)  Time: 0.568s,   56.29/s  (0.432s,   74.04/s)  LR: 1.000e-05  Data: 0.146 (0.005)\n",
            "Test: [   0/312]  Time: 1.179 (1.179)  Loss:  0.1329 (0.1329)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.148 (0.161)  Loss:  0.0989 (0.1663)  Acc@1: 100.0000 (98.4069)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.148)  Loss:  0.4731 (0.2096)  Acc@1: 90.6250 (97.3082)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.139 (0.144)  Loss:  0.1218 (0.2672)  Acc@1: 100.0000 (95.9437)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.136 (0.142)  Loss:  0.3225 (0.3347)  Acc@1: 93.7500 (92.6617)  Acc@5: 100.0000 (99.9534)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1940 (0.3255)  Acc@1: 100.0000 (93.0652)  Acc@5: 100.0000 (99.9128)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  1.0107 (0.3197)  Acc@1: 71.8750 (93.4385)  Acc@5: 90.6250 (99.8443)\n",
            "Test: [ 312/312]  Time: 0.206 (0.140)  Loss:  0.1315 (0.3160)  Acc@1: 100.0000 (93.5900)  Acc@5: 100.0000 (99.8400)\n",
            "Test (EMA): [   0/312]  Time: 1.109 (1.109)  Loss:  1.7861 (1.7861)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.158)  Loss:  2.0469 (1.8865)  Acc@1:  0.0000 (61.9485)  Acc@5: 100.0000 (99.8162)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.147)  Loss:  2.5469 (2.0077)  Acc@1:  0.0000 (31.3428)  Acc@5:  0.0000 (97.2772)\n",
            "Test (EMA): [ 150/312]  Time: 0.160 (0.143)  Loss:  2.0645 (2.1173)  Acc@1:  0.0000 (20.9644)  Acc@5: 100.0000 (79.0356)\n",
            "Test (EMA): [ 200/312]  Time: 0.140 (0.141)  Loss:  2.4805 (2.1879)  Acc@1:  0.0000 (15.7494)  Acc@5:  0.0000 (64.1480)\n",
            "Test (EMA): [ 250/312]  Time: 0.141 (0.140)  Loss:  2.3906 (2.2170)  Acc@1:  0.0000 (12.6121)  Acc@5: 53.1250 (64.1683)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.3457 (2.2584)  Acc@1:  0.0000 (10.5170)  Acc@5: 68.7500 (57.0806)\n",
            "Test (EMA): [ 312/312]  Time: 0.208 (0.139)  Loss:  2.3398 (2.2612)  Acc@1:  0.0000 (10.1300)  Acc@5: 50.0000 (57.0000)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 5 [   0/1875 (  0%)]  Loss:  1.465394 (1.4654)  Time: 2.397s,   13.35/s  (2.397s,   13.35/s)  LR: 1.000e-05  Data: 1.551 (1.551)\n",
            "Train: 5 [  50/1875 (  3%)]  Loss:  2.207826 (1.8599)  Time: 0.430s,   74.40/s  (0.470s,   68.11/s)  LR: 1.000e-05  Data: 0.004 (0.034)\n",
            "Train: 5 [ 100/1875 (  5%)]  Loss:  2.034964 (1.7579)  Time: 0.429s,   74.54/s  (0.451s,   71.03/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 5 [ 150/1875 (  8%)]  Loss:  2.246856 (1.7701)  Time: 0.430s,   74.43/s  (0.444s,   72.00/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 5 [ 200/1875 ( 11%)]  Loss:  1.652948 (1.7962)  Time: 0.430s,   74.37/s  (0.441s,   72.55/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 5 [ 250/1875 ( 13%)]  Loss:  1.304687 (1.8114)  Time: 0.439s,   72.87/s  (0.439s,   72.88/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 5 [ 300/1875 ( 16%)]  Loss:  1.606798 (1.8113)  Time: 0.429s,   74.68/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 5 [ 350/1875 ( 19%)]  Loss:  1.343284 (1.7949)  Time: 0.429s,   74.58/s  (0.437s,   73.24/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 5 [ 400/1875 ( 21%)]  Loss:  2.045144 (1.7786)  Time: 0.431s,   74.19/s  (0.436s,   73.36/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 5 [ 450/1875 ( 24%)]  Loss:  1.303822 (1.7757)  Time: 0.430s,   74.36/s  (0.436s,   73.45/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 5 [ 500/1875 ( 27%)]  Loss:  1.356286 (1.7743)  Time: 0.429s,   74.51/s  (0.435s,   73.53/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 550/1875 ( 29%)]  Loss:  2.259922 (1.7913)  Time: 0.432s,   74.15/s  (0.435s,   73.60/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 600/1875 ( 32%)]  Loss:  1.685655 (1.8042)  Time: 0.431s,   74.21/s  (0.434s,   73.65/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 650/1875 ( 35%)]  Loss:  1.335347 (1.7856)  Time: 0.431s,   74.25/s  (0.434s,   73.68/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 700/1875 ( 37%)]  Loss:  1.970954 (1.7768)  Time: 0.430s,   74.41/s  (0.434s,   73.72/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 750/1875 ( 40%)]  Loss:  1.416180 (1.7688)  Time: 0.433s,   73.93/s  (0.434s,   73.75/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 800/1875 ( 43%)]  Loss:  1.652945 (1.7828)  Time: 0.433s,   73.88/s  (0.434s,   73.78/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 850/1875 ( 45%)]  Loss:  2.068379 (1.7813)  Time: 0.432s,   74.08/s  (0.434s,   73.80/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 900/1875 ( 48%)]  Loss:  2.072610 (1.7894)  Time: 0.431s,   74.32/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 950/1875 ( 51%)]  Loss:  1.752913 (1.7951)  Time: 0.431s,   74.20/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1000/1875 ( 53%)]  Loss:  1.506922 (1.7872)  Time: 0.430s,   74.44/s  (0.433s,   73.86/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1050/1875 ( 56%)]  Loss:  1.545508 (1.7805)  Time: 0.429s,   74.66/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1100/1875 ( 59%)]  Loss:  1.417525 (1.7752)  Time: 0.435s,   73.48/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 5 [1150/1875 ( 61%)]  Loss:  1.358524 (1.7712)  Time: 0.431s,   74.32/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1200/1875 ( 64%)]  Loss:  2.054459 (1.7739)  Time: 0.431s,   74.18/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 5 [1250/1875 ( 67%)]  Loss:  1.721693 (1.7696)  Time: 0.431s,   74.24/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1300/1875 ( 69%)]  Loss:  2.086853 (1.7706)  Time: 0.438s,   73.01/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1350/1875 ( 72%)]  Loss:  2.098246 (1.7672)  Time: 0.431s,   74.31/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1400/1875 ( 75%)]  Loss:  1.962762 (1.7672)  Time: 0.428s,   74.71/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1450/1875 ( 77%)]  Loss:  1.922853 (1.7708)  Time: 0.433s,   73.95/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1500/1875 ( 80%)]  Loss:  1.233452 (1.7647)  Time: 0.429s,   74.62/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1550/1875 ( 83%)]  Loss:  1.322393 (1.7627)  Time: 0.430s,   74.38/s  (0.433s,   73.98/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1600/1875 ( 85%)]  Loss:  2.030828 (1.7643)  Time: 0.433s,   73.89/s  (0.433s,   73.98/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1650/1875 ( 88%)]  Loss:  2.248610 (1.7627)  Time: 0.430s,   74.45/s  (0.432s,   73.99/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 5 [1700/1875 ( 91%)]  Loss:  1.424272 (1.7595)  Time: 0.431s,   74.19/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1750/1875 ( 93%)]  Loss:  2.067798 (1.7630)  Time: 0.431s,   74.19/s  (0.432s,   74.00/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1800/1875 ( 96%)]  Loss:  2.157927 (1.7647)  Time: 0.431s,   74.31/s  (0.432s,   74.01/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1850/1875 ( 99%)]  Loss:  1.588610 (1.7608)  Time: 0.429s,   74.59/s  (0.432s,   74.02/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1874/1875 (100%)]  Loss:  1.555587 (1.7592)  Time: 0.569s,   56.21/s  (0.432s,   74.01/s)  LR: 1.000e-05  Data: 0.146 (0.005)\n",
            "Test: [   0/312]  Time: 1.233 (1.233)  Loss:  0.2123 (0.2123)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.161)  Loss:  0.1017 (0.2192)  Acc@1: 100.0000 (97.8554)  Acc@5: 100.0000 (99.9387)\n",
            "Test: [ 100/312]  Time: 0.131 (0.149)  Loss:  0.4009 (0.2118)  Acc@1: 93.7500 (97.5248)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.137 (0.144)  Loss:  0.1077 (0.2428)  Acc@1: 100.0000 (96.7715)  Acc@5: 100.0000 (99.9379)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.3281 (0.3236)  Acc@1: 90.6250 (92.8483)  Acc@5: 100.0000 (99.9223)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1676 (0.3128)  Acc@1: 100.0000 (93.4014)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.8311 (0.3092)  Acc@1: 71.8750 (93.7708)  Acc@5: 96.8750 (99.9169)\n",
            "Test: [ 312/312]  Time: 0.207 (0.140)  Loss:  0.2078 (0.3078)  Acc@1: 100.0000 (93.8900)  Acc@5: 100.0000 (99.9200)\n",
            "Test (EMA): [   0/312]  Time: 1.289 (1.289)  Loss:  1.7656 (1.7656)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.160)  Loss:  1.9678 (1.8483)  Acc@1: 15.6250 (69.0564)  Acc@5: 100.0000 (99.8162)\n",
            "Test (EMA): [ 100/312]  Time: 0.137 (0.148)  Loss:  2.5234 (1.9674)  Acc@1:  0.0000 (35.9220)  Acc@5:  0.0000 (97.2772)\n",
            "Test (EMA): [ 150/312]  Time: 0.134 (0.144)  Loss:  2.0098 (2.0783)  Acc@1:  0.0000 (24.0273)  Acc@5: 100.0000 (79.0563)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  2.4668 (2.1564)  Acc@1:  0.0000 (18.0504)  Acc@5:  0.0000 (64.2102)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.140)  Loss:  2.3535 (2.1839)  Acc@1:  0.0000 (14.4547)  Acc@5: 53.1250 (64.2181)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.3301 (2.2271)  Acc@1:  0.0000 (12.0536)  Acc@5: 93.7500 (58.1914)\n",
            "Test (EMA): [ 312/312]  Time: 0.207 (0.139)  Loss:  2.3184 (2.2303)  Acc@1:  0.0000 (11.6100)  Acc@5: 68.7500 (58.5600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 6 [   0/1875 (  0%)]  Loss:  1.200745 (1.2007)  Time: 2.408s,   13.29/s  (2.408s,   13.29/s)  LR: 1.000e-05  Data: 1.428 (1.428)\n",
            "Train: 6 [  50/1875 (  3%)]  Loss:  2.149276 (1.8335)  Time: 0.429s,   74.66/s  (0.471s,   67.88/s)  LR: 1.000e-05  Data: 0.004 (0.032)\n",
            "Train: 6 [ 100/1875 (  5%)]  Loss:  1.930465 (1.7254)  Time: 0.433s,   73.87/s  (0.452s,   70.87/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 6 [ 150/1875 (  8%)]  Loss:  1.938898 (1.7201)  Time: 0.429s,   74.56/s  (0.445s,   71.92/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 6 [ 200/1875 ( 11%)]  Loss:  1.867473 (1.7582)  Time: 0.432s,   74.03/s  (0.442s,   72.46/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 6 [ 250/1875 ( 13%)]  Loss:  1.562339 (1.7790)  Time: 0.431s,   74.20/s  (0.440s,   72.80/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 6 [ 300/1875 ( 16%)]  Loss:  1.607260 (1.7804)  Time: 0.431s,   74.26/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 6 [ 350/1875 ( 19%)]  Loss:  1.382899 (1.7659)  Time: 0.432s,   74.10/s  (0.437s,   73.17/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 6 [ 400/1875 ( 21%)]  Loss:  1.975616 (1.7536)  Time: 0.430s,   74.35/s  (0.437s,   73.30/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 6 [ 450/1875 ( 24%)]  Loss:  1.463295 (1.7519)  Time: 0.429s,   74.52/s  (0.436s,   73.38/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 500/1875 ( 27%)]  Loss:  1.405485 (1.7520)  Time: 0.429s,   74.51/s  (0.436s,   73.45/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 550/1875 ( 29%)]  Loss:  2.124600 (1.7732)  Time: 0.432s,   74.11/s  (0.435s,   73.51/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 600/1875 ( 32%)]  Loss:  1.723959 (1.7856)  Time: 0.432s,   74.00/s  (0.435s,   73.57/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 650/1875 ( 35%)]  Loss:  1.192630 (1.7640)  Time: 0.430s,   74.49/s  (0.435s,   73.62/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 700/1875 ( 37%)]  Loss:  1.677768 (1.7536)  Time: 0.431s,   74.29/s  (0.434s,   73.66/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 750/1875 ( 40%)]  Loss:  1.259084 (1.7470)  Time: 0.432s,   74.11/s  (0.434s,   73.70/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 800/1875 ( 43%)]  Loss:  1.859239 (1.7587)  Time: 0.434s,   73.70/s  (0.434s,   73.73/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 6 [ 850/1875 ( 45%)]  Loss:  2.055986 (1.7554)  Time: 0.431s,   74.28/s  (0.434s,   73.75/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 900/1875 ( 48%)]  Loss:  2.086248 (1.7638)  Time: 0.429s,   74.66/s  (0.434s,   73.77/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 950/1875 ( 51%)]  Loss:  1.807091 (1.7708)  Time: 0.444s,   72.12/s  (0.434s,   73.79/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1000/1875 ( 53%)]  Loss:  1.291651 (1.7638)  Time: 0.431s,   74.27/s  (0.434s,   73.81/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1050/1875 ( 56%)]  Loss:  1.626371 (1.7552)  Time: 0.430s,   74.41/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1100/1875 ( 59%)]  Loss:  1.317721 (1.7483)  Time: 0.429s,   74.56/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1150/1875 ( 61%)]  Loss:  1.465890 (1.7438)  Time: 0.438s,   73.13/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1200/1875 ( 64%)]  Loss:  2.010349 (1.7449)  Time: 0.430s,   74.35/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 6 [1250/1875 ( 67%)]  Loss:  1.308137 (1.7415)  Time: 0.430s,   74.47/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1300/1875 ( 69%)]  Loss:  1.975722 (1.7435)  Time: 0.431s,   74.32/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1350/1875 ( 72%)]  Loss:  1.992103 (1.7408)  Time: 0.432s,   74.06/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1400/1875 ( 75%)]  Loss:  2.033360 (1.7410)  Time: 0.433s,   73.94/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1450/1875 ( 77%)]  Loss:  2.037448 (1.7441)  Time: 0.433s,   73.98/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1500/1875 ( 80%)]  Loss:  1.379736 (1.7384)  Time: 0.431s,   74.31/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 6 [1550/1875 ( 83%)]  Loss:  1.305075 (1.7355)  Time: 0.433s,   73.96/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1600/1875 ( 85%)]  Loss:  2.032213 (1.7376)  Time: 0.431s,   74.33/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1650/1875 ( 88%)]  Loss:  2.137985 (1.7365)  Time: 0.439s,   72.85/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1700/1875 ( 91%)]  Loss:  1.368755 (1.7330)  Time: 0.430s,   74.38/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1750/1875 ( 93%)]  Loss:  2.239918 (1.7358)  Time: 0.431s,   74.22/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1800/1875 ( 96%)]  Loss:  2.033528 (1.7388)  Time: 0.431s,   74.24/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1850/1875 ( 99%)]  Loss:  1.469254 (1.7352)  Time: 0.429s,   74.62/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1874/1875 (100%)]  Loss:  1.174435 (1.7339)  Time: 0.566s,   56.54/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.145 (0.005)\n",
            "Test: [   0/312]  Time: 1.221 (1.221)  Loss:  0.1603 (0.1603)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.138 (0.160)  Loss:  0.1029 (0.1850)  Acc@1: 100.0000 (98.2843)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.138 (0.148)  Loss:  0.3528 (0.1999)  Acc@1: 93.7500 (97.8032)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1140 (0.2311)  Acc@1: 100.0000 (97.1647)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.143 (0.142)  Loss:  0.3354 (0.2860)  Acc@1: 90.6250 (94.7761)  Acc@5: 100.0000 (99.9534)\n",
            "Test: [ 250/312]  Time: 0.138 (0.140)  Loss:  0.1804 (0.2860)  Acc@1: 96.8750 (94.9577)  Acc@5: 100.0000 (99.9626)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.6006 (0.2840)  Acc@1: 84.3750 (95.2139)  Acc@5: 96.8750 (99.9481)\n",
            "Test: [ 312/312]  Time: 0.208 (0.140)  Loss:  0.1632 (0.2816)  Acc@1: 100.0000 (95.3200)  Acc@5: 100.0000 (99.9500)\n",
            "Test (EMA): [   0/312]  Time: 1.163 (1.163)  Loss:  1.7344 (1.7344)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.139 (0.161)  Loss:  1.8750 (1.8005)  Acc@1: 78.1250 (89.1544)  Acc@5: 100.0000 (99.8775)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  2.4492 (1.9152)  Acc@1:  0.0000 (51.2686)  Acc@5: 34.3750 (98.2054)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.144)  Loss:  1.9473 (2.0196)  Acc@1: 37.5000 (38.7003)  Acc@5: 100.0000 (87.8518)\n",
            "Test (EMA): [ 200/312]  Time: 0.132 (0.142)  Loss:  2.4277 (2.1029)  Acc@1:  0.0000 (30.4726)  Acc@5:  6.2500 (71.8439)\n",
            "Test (EMA): [ 250/312]  Time: 0.133 (0.140)  Loss:  2.3047 (2.1305)  Acc@1:  0.0000 (24.4024)  Acc@5: 53.1250 (71.0159)\n",
            "Test (EMA): [ 300/312]  Time: 0.131 (0.140)  Loss:  2.2969 (2.1755)  Acc@1:  0.0000 (20.3488)  Acc@5: 90.6250 (65.3966)\n",
            "Test (EMA): [ 312/312]  Time: 0.210 (0.139)  Loss:  2.2715 (2.1787)  Acc@1:  0.0000 (19.6000)  Acc@5: 100.0000 (66.6100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-6.pth.tar', 19.6)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 7 [   0/1875 (  0%)]  Loss:  1.435407 (1.4354)  Time: 2.474s,   12.93/s  (2.474s,   12.93/s)  LR: 1.000e-05  Data: 1.389 (1.389)\n",
            "Train: 7 [  50/1875 (  3%)]  Loss:  2.032316 (1.8122)  Time: 0.429s,   74.54/s  (0.471s,   67.92/s)  LR: 1.000e-05  Data: 0.004 (0.032)\n",
            "Train: 7 [ 100/1875 (  5%)]  Loss:  2.074396 (1.7217)  Time: 0.433s,   73.90/s  (0.452s,   70.87/s)  LR: 1.000e-05  Data: 0.004 (0.018)\n",
            "Train: 7 [ 150/1875 (  8%)]  Loss:  2.257315 (1.7289)  Time: 0.429s,   74.62/s  (0.445s,   71.96/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 7 [ 200/1875 ( 11%)]  Loss:  1.781529 (1.7584)  Time: 0.431s,   74.28/s  (0.441s,   72.52/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 7 [ 250/1875 ( 13%)]  Loss:  1.292813 (1.7732)  Time: 0.431s,   74.25/s  (0.439s,   72.85/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 7 [ 300/1875 ( 16%)]  Loss:  1.125319 (1.7755)  Time: 0.432s,   74.06/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 7 [ 350/1875 ( 19%)]  Loss:  1.454065 (1.7577)  Time: 0.429s,   74.64/s  (0.437s,   73.25/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 400/1875 ( 21%)]  Loss:  1.879424 (1.7450)  Time: 0.429s,   74.61/s  (0.436s,   73.36/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 450/1875 ( 24%)]  Loss:  1.282634 (1.7406)  Time: 0.432s,   74.01/s  (0.436s,   73.45/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 500/1875 ( 27%)]  Loss:  1.247070 (1.7404)  Time: 0.437s,   73.19/s  (0.435s,   73.53/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 550/1875 ( 29%)]  Loss:  2.071183 (1.7586)  Time: 0.429s,   74.57/s  (0.435s,   73.59/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 600/1875 ( 32%)]  Loss:  1.703446 (1.7735)  Time: 0.430s,   74.36/s  (0.435s,   73.65/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 650/1875 ( 35%)]  Loss:  1.496839 (1.7513)  Time: 0.435s,   73.55/s  (0.434s,   73.68/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 700/1875 ( 37%)]  Loss:  1.849925 (1.7391)  Time: 0.430s,   74.39/s  (0.434s,   73.72/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 750/1875 ( 40%)]  Loss:  1.386401 (1.7331)  Time: 0.430s,   74.39/s  (0.434s,   73.74/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 800/1875 ( 43%)]  Loss:  1.523772 (1.7455)  Time: 0.429s,   74.53/s  (0.434s,   73.78/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 850/1875 ( 45%)]  Loss:  2.154411 (1.7422)  Time: 0.432s,   74.05/s  (0.434s,   73.80/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 900/1875 ( 48%)]  Loss:  2.126373 (1.7519)  Time: 0.436s,   73.42/s  (0.434s,   73.81/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 7 [ 950/1875 ( 51%)]  Loss:  1.746381 (1.7592)  Time: 0.435s,   73.61/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1000/1875 ( 53%)]  Loss:  1.311000 (1.7531)  Time: 0.432s,   74.06/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1050/1875 ( 56%)]  Loss:  1.377815 (1.7462)  Time: 0.436s,   73.44/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.010 (0.006)\n",
            "Train: 7 [1100/1875 ( 59%)]  Loss:  1.235050 (1.7401)  Time: 0.431s,   74.17/s  (0.433s,   73.86/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1150/1875 ( 61%)]  Loss:  1.406138 (1.7357)  Time: 0.432s,   74.11/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1200/1875 ( 64%)]  Loss:  1.885077 (1.7370)  Time: 0.431s,   74.28/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1250/1875 ( 67%)]  Loss:  1.466468 (1.7337)  Time: 0.439s,   72.88/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 7 [1300/1875 ( 69%)]  Loss:  2.064873 (1.7353)  Time: 0.431s,   74.19/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1350/1875 ( 72%)]  Loss:  2.056421 (1.7323)  Time: 0.431s,   74.23/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 7 [1400/1875 ( 75%)]  Loss:  2.007553 (1.7316)  Time: 0.431s,   74.19/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1450/1875 ( 77%)]  Loss:  2.052325 (1.7342)  Time: 0.431s,   74.28/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1500/1875 ( 80%)]  Loss:  1.214738 (1.7259)  Time: 0.438s,   72.98/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1550/1875 ( 83%)]  Loss:  1.340643 (1.7245)  Time: 0.431s,   74.32/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1600/1875 ( 85%)]  Loss:  2.035004 (1.7273)  Time: 0.432s,   74.15/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1650/1875 ( 88%)]  Loss:  2.086931 (1.7250)  Time: 0.431s,   74.28/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1700/1875 ( 91%)]  Loss:  1.321794 (1.7204)  Time: 0.429s,   74.53/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1750/1875 ( 93%)]  Loss:  2.070818 (1.7241)  Time: 0.431s,   74.17/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1800/1875 ( 96%)]  Loss:  2.180092 (1.7256)  Time: 0.429s,   74.52/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1850/1875 ( 99%)]  Loss:  1.498117 (1.7209)  Time: 0.431s,   74.30/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1874/1875 (100%)]  Loss:  1.366794 (1.7192)  Time: 0.568s,   56.30/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.147 (0.005)\n",
            "Test: [   0/312]  Time: 1.214 (1.214)  Loss:  0.1711 (0.1711)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.161)  Loss:  0.1069 (0.2037)  Acc@1: 100.0000 (97.7328)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.138 (0.149)  Loss:  0.4482 (0.2478)  Acc@1: 90.6250 (96.1324)  Acc@5: 100.0000 (99.8762)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1115 (0.2863)  Acc@1: 100.0000 (94.7227)  Acc@5: 100.0000 (99.8551)\n",
            "Test: [ 200/312]  Time: 0.141 (0.142)  Loss:  0.1627 (0.3017)  Acc@1: 100.0000 (93.9988)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1614 (0.2889)  Acc@1: 100.0000 (94.5468)  Acc@5: 100.0000 (99.8879)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4519 (0.2828)  Acc@1: 90.6250 (94.9855)  Acc@5: 100.0000 (99.9066)\n",
            "Test: [ 312/312]  Time: 0.210 (0.140)  Loss:  0.1631 (0.2800)  Acc@1: 100.0000 (95.1100)  Acc@5: 100.0000 (99.9100)\n",
            "Test (EMA): [   0/312]  Time: 1.169 (1.169)  Loss:  1.6748 (1.6748)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.143 (0.160)  Loss:  1.7588 (1.7288)  Acc@1: 96.8750 (97.3039)  Acc@5: 100.0000 (99.8775)\n",
            "Test (EMA): [ 100/312]  Time: 0.132 (0.148)  Loss:  2.3301 (1.8373)  Acc@1:  0.0000 (67.1411)  Acc@5: 71.8750 (99.1955)\n",
            "Test (EMA): [ 150/312]  Time: 0.138 (0.144)  Loss:  1.8701 (1.9330)  Acc@1: 84.3750 (57.5331)  Acc@5: 100.0000 (96.0679)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.141)  Loss:  2.3652 (2.0198)  Acc@1:  0.0000 (47.5435)  Acc@5: 68.7500 (86.8470)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.140)  Loss:  2.2305 (2.0500)  Acc@1:  3.1250 (38.9442)  Acc@5: 53.1250 (88.1723)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.139)  Loss:  2.2461 (2.0954)  Acc@1:  0.0000 (32.4751)  Acc@5: 84.3750 (80.6478)\n",
            "Test (EMA): [ 312/312]  Time: 0.217 (0.139)  Loss:  2.1992 (2.0988)  Acc@1:  0.0000 (31.2800)  Acc@5: 100.0000 (81.3400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-7.pth.tar', 31.28)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-6.pth.tar', 19.6)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 8 [   0/1875 (  0%)]  Loss:  1.306137 (1.3061)  Time: 2.387s,   13.40/s  (2.387s,   13.40/s)  LR: 1.000e-05  Data: 1.466 (1.466)\n",
            "Train: 8 [  50/1875 (  3%)]  Loss:  2.099613 (1.7521)  Time: 0.429s,   74.55/s  (0.470s,   68.06/s)  LR: 1.000e-05  Data: 0.004 (0.034)\n",
            "Train: 8 [ 100/1875 (  5%)]  Loss:  2.091340 (1.6851)  Time: 0.433s,   73.95/s  (0.451s,   70.92/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 8 [ 150/1875 (  8%)]  Loss:  1.875481 (1.7008)  Time: 0.430s,   74.36/s  (0.445s,   71.91/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 8 [ 200/1875 ( 11%)]  Loss:  1.686989 (1.7376)  Time: 0.430s,   74.51/s  (0.441s,   72.48/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 8 [ 250/1875 ( 13%)]  Loss:  1.350382 (1.7552)  Time: 0.431s,   74.24/s  (0.439s,   72.82/s)  LR: 1.000e-05  Data: 0.005 (0.010)\n",
            "Train: 8 [ 300/1875 ( 16%)]  Loss:  1.192174 (1.7538)  Time: 0.433s,   73.96/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 8 [ 350/1875 ( 19%)]  Loss:  1.399595 (1.7322)  Time: 0.429s,   74.60/s  (0.437s,   73.20/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 8 [ 400/1875 ( 21%)]  Loss:  1.829497 (1.7194)  Time: 0.431s,   74.30/s  (0.436s,   73.32/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 450/1875 ( 24%)]  Loss:  1.390164 (1.7158)  Time: 0.429s,   74.67/s  (0.436s,   73.42/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 500/1875 ( 27%)]  Loss:  1.402931 (1.7182)  Time: 0.432s,   74.02/s  (0.435s,   73.50/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 550/1875 ( 29%)]  Loss:  2.062172 (1.7380)  Time: 0.431s,   74.17/s  (0.435s,   73.56/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 600/1875 ( 32%)]  Loss:  1.595703 (1.7531)  Time: 0.438s,   73.09/s  (0.435s,   73.60/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 650/1875 ( 35%)]  Loss:  1.306298 (1.7297)  Time: 0.431s,   74.27/s  (0.435s,   73.64/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 700/1875 ( 37%)]  Loss:  1.832067 (1.7186)  Time: 0.431s,   74.16/s  (0.434s,   73.67/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 8 [ 750/1875 ( 40%)]  Loss:  1.198129 (1.7150)  Time: 0.430s,   74.43/s  (0.434s,   73.71/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 800/1875 ( 43%)]  Loss:  1.747320 (1.7287)  Time: 0.431s,   74.17/s  (0.434s,   73.74/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 8 [ 850/1875 ( 45%)]  Loss:  2.057110 (1.7277)  Time: 0.432s,   74.07/s  (0.434s,   73.76/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 8 [ 900/1875 ( 48%)]  Loss:  2.165453 (1.7353)  Time: 0.432s,   74.11/s  (0.434s,   73.78/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 950/1875 ( 51%)]  Loss:  1.764724 (1.7440)  Time: 0.432s,   74.10/s  (0.434s,   73.81/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1000/1875 ( 53%)]  Loss:  1.244072 (1.7363)  Time: 0.432s,   74.09/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1050/1875 ( 56%)]  Loss:  1.590268 (1.7280)  Time: 0.429s,   74.65/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1100/1875 ( 59%)]  Loss:  1.484971 (1.7216)  Time: 0.432s,   74.09/s  (0.433s,   73.86/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1150/1875 ( 61%)]  Loss:  1.111887 (1.7169)  Time: 0.428s,   74.71/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1200/1875 ( 64%)]  Loss:  1.905372 (1.7190)  Time: 0.435s,   73.59/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1250/1875 ( 67%)]  Loss:  1.278462 (1.7153)  Time: 0.430s,   74.34/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1300/1875 ( 69%)]  Loss:  2.228328 (1.7169)  Time: 0.431s,   74.26/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1350/1875 ( 72%)]  Loss:  2.038310 (1.7151)  Time: 0.431s,   74.32/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1400/1875 ( 75%)]  Loss:  1.921819 (1.7140)  Time: 0.435s,   73.64/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1450/1875 ( 77%)]  Loss:  1.986786 (1.7174)  Time: 0.431s,   74.22/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1500/1875 ( 80%)]  Loss:  1.142372 (1.7097)  Time: 0.432s,   74.07/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1550/1875 ( 83%)]  Loss:  1.137623 (1.7071)  Time: 0.430s,   74.41/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1600/1875 ( 85%)]  Loss:  2.053652 (1.7092)  Time: 0.429s,   74.52/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1650/1875 ( 88%)]  Loss:  2.230565 (1.7069)  Time: 0.430s,   74.41/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1700/1875 ( 91%)]  Loss:  1.435203 (1.7029)  Time: 0.430s,   74.42/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1750/1875 ( 93%)]  Loss:  1.926967 (1.7067)  Time: 0.432s,   74.03/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1800/1875 ( 96%)]  Loss:  2.202065 (1.7092)  Time: 0.432s,   74.12/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 8 [1850/1875 ( 99%)]  Loss:  1.385492 (1.7054)  Time: 0.432s,   74.08/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1874/1875 (100%)]  Loss:  1.379261 (1.7035)  Time: 0.580s,   55.16/s  (0.433s,   73.97/s)  LR: 1.000e-05  Data: 0.151 (0.005)\n",
            "Test: [   0/312]  Time: 1.277 (1.277)  Loss:  0.1290 (0.1290)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.161)  Loss:  0.0938 (0.1636)  Acc@1: 100.0000 (98.4681)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.138 (0.150)  Loss:  0.3728 (0.1832)  Acc@1: 87.5000 (97.6485)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.132 (0.145)  Loss:  0.1116 (0.2321)  Acc@1: 100.0000 (96.0679)  Acc@5: 100.0000 (99.9379)\n",
            "Test: [ 200/312]  Time: 0.132 (0.143)  Loss:  0.1970 (0.2545)  Acc@1: 96.8750 (95.2270)  Acc@5: 100.0000 (99.9067)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1621 (0.2480)  Acc@1: 96.8750 (95.4806)  Acc@5: 100.0000 (99.9253)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.5049 (0.2480)  Acc@1: 87.5000 (95.6707)  Acc@5: 100.0000 (99.9273)\n",
            "Test: [ 312/312]  Time: 0.219 (0.140)  Loss:  0.1444 (0.2461)  Acc@1: 100.0000 (95.7600)  Acc@5: 100.0000 (99.9300)\n",
            "Test (EMA): [   0/312]  Time: 1.218 (1.218)  Loss:  1.5684 (1.5684)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.161)  Loss:  1.6074 (1.6180)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (99.8775)\n",
            "Test (EMA): [ 100/312]  Time: 0.138 (0.149)  Loss:  2.1719 (1.7261)  Acc@1:  0.0000 (81.8998)  Acc@5: 84.3750 (99.6597)\n",
            "Test (EMA): [ 150/312]  Time: 0.142 (0.145)  Loss:  1.7656 (1.8123)  Acc@1: 100.0000 (68.4810)  Acc@5: 100.0000 (99.0687)\n",
            "Test (EMA): [ 200/312]  Time: 0.140 (0.143)  Loss:  2.2715 (1.9016)  Acc@1:  0.0000 (56.1412)  Acc@5: 90.6250 (96.0665)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.141)  Loss:  2.1230 (1.9363)  Acc@1: 21.8750 (50.9960)  Acc@5: 93.7500 (96.4019)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  2.1797 (1.9815)  Acc@1:  6.2500 (43.0440)  Acc@5: 65.6250 (94.8816)\n",
            "Test (EMA): [ 312/312]  Time: 0.210 (0.140)  Loss:  2.1055 (1.9855)  Acc@1:  0.0000 (41.7800)  Acc@5: 100.0000 (95.0600)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-8.pth.tar', 41.78)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-7.pth.tar', 31.28)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-6.pth.tar', 19.6)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 9 [   0/1875 (  0%)]  Loss:  1.019377 (1.0194)  Time: 2.381s,   13.44/s  (2.381s,   13.44/s)  LR: 1.000e-05  Data: 1.379 (1.379)\n",
            "Train: 9 [  50/1875 (  3%)]  Loss:  2.207270 (1.7725)  Time: 0.434s,   73.80/s  (0.471s,   67.91/s)  LR: 1.000e-05  Data: 0.005 (0.032)\n",
            "Train: 9 [ 100/1875 (  5%)]  Loss:  1.913529 (1.6710)  Time: 0.431s,   74.23/s  (0.452s,   70.86/s)  LR: 1.000e-05  Data: 0.004 (0.018)\n",
            "Train: 9 [ 150/1875 (  8%)]  Loss:  2.138040 (1.6894)  Time: 0.432s,   74.12/s  (0.445s,   71.92/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 9 [ 200/1875 ( 11%)]  Loss:  1.690681 (1.7288)  Time: 0.431s,   74.22/s  (0.442s,   72.47/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 9 [ 250/1875 ( 13%)]  Loss:  1.185708 (1.7452)  Time: 0.432s,   74.05/s  (0.440s,   72.80/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 9 [ 300/1875 ( 16%)]  Loss:  1.242004 (1.7452)  Time: 0.432s,   74.11/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 9 [ 350/1875 ( 19%)]  Loss:  1.191498 (1.7268)  Time: 0.430s,   74.36/s  (0.437s,   73.17/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 9 [ 400/1875 ( 21%)]  Loss:  1.835300 (1.7110)  Time: 0.431s,   74.26/s  (0.437s,   73.29/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 9 [ 450/1875 ( 24%)]  Loss:  1.291002 (1.7110)  Time: 0.433s,   73.88/s  (0.436s,   73.39/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 500/1875 ( 27%)]  Loss:  1.212183 (1.7103)  Time: 0.430s,   74.46/s  (0.436s,   73.46/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 550/1875 ( 29%)]  Loss:  2.261645 (1.7319)  Time: 0.433s,   73.86/s  (0.435s,   73.52/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 600/1875 ( 32%)]  Loss:  1.567553 (1.7451)  Time: 0.429s,   74.62/s  (0.435s,   73.57/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 650/1875 ( 35%)]  Loss:  1.135945 (1.7229)  Time: 0.431s,   74.18/s  (0.435s,   73.60/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 700/1875 ( 37%)]  Loss:  2.078993 (1.7106)  Time: 0.433s,   73.94/s  (0.435s,   73.64/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 750/1875 ( 40%)]  Loss:  1.326621 (1.7043)  Time: 0.429s,   74.56/s  (0.434s,   73.67/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 800/1875 ( 43%)]  Loss:  2.005607 (1.7174)  Time: 0.432s,   74.14/s  (0.434s,   73.69/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 850/1875 ( 45%)]  Loss:  2.245279 (1.7149)  Time: 0.430s,   74.42/s  (0.434s,   73.72/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 900/1875 ( 48%)]  Loss:  2.061557 (1.7241)  Time: 0.437s,   73.25/s  (0.434s,   73.75/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 950/1875 ( 51%)]  Loss:  1.587665 (1.7317)  Time: 0.433s,   73.97/s  (0.434s,   73.76/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1000/1875 ( 53%)]  Loss:  1.137788 (1.7236)  Time: 0.431s,   74.25/s  (0.434s,   73.77/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1050/1875 ( 56%)]  Loss:  1.314666 (1.7160)  Time: 0.431s,   74.19/s  (0.434s,   73.79/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1100/1875 ( 59%)]  Loss:  1.277499 (1.7106)  Time: 0.430s,   74.42/s  (0.434s,   73.80/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1150/1875 ( 61%)]  Loss:  1.108913 (1.7049)  Time: 0.431s,   74.33/s  (0.434s,   73.81/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1200/1875 ( 64%)]  Loss:  1.812663 (1.7073)  Time: 0.431s,   74.27/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1250/1875 ( 67%)]  Loss:  1.130429 (1.7036)  Time: 0.434s,   73.81/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1300/1875 ( 69%)]  Loss:  2.331548 (1.7066)  Time: 0.432s,   74.04/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1350/1875 ( 72%)]  Loss:  2.123791 (1.7043)  Time: 0.430s,   74.48/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1400/1875 ( 75%)]  Loss:  1.939462 (1.7039)  Time: 0.431s,   74.33/s  (0.433s,   73.86/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1450/1875 ( 77%)]  Loss:  2.043736 (1.7066)  Time: 0.431s,   74.20/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1500/1875 ( 80%)]  Loss:  1.217561 (1.6999)  Time: 0.430s,   74.40/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1550/1875 ( 83%)]  Loss:  1.056376 (1.6971)  Time: 0.432s,   74.08/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1600/1875 ( 85%)]  Loss:  1.966629 (1.6997)  Time: 0.431s,   74.24/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1650/1875 ( 88%)]  Loss:  2.175938 (1.6980)  Time: 0.431s,   74.23/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1700/1875 ( 91%)]  Loss:  0.927816 (1.6941)  Time: 0.435s,   73.55/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1750/1875 ( 93%)]  Loss:  2.206007 (1.6977)  Time: 0.433s,   73.90/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1800/1875 ( 96%)]  Loss:  2.135876 (1.7008)  Time: 0.429s,   74.55/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1850/1875 ( 99%)]  Loss:  1.225433 (1.6970)  Time: 0.429s,   74.56/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1874/1875 (100%)]  Loss:  1.390413 (1.6948)  Time: 0.572s,   55.95/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.149 (0.005)\n",
            "Test: [   0/312]  Time: 1.105 (1.105)  Loss:  0.1632 (0.1632)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.138 (0.161)  Loss:  0.1044 (0.1890)  Acc@1: 100.0000 (98.3456)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.148)  Loss:  0.1964 (0.1949)  Acc@1: 96.8750 (97.8960)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1187 (0.2112)  Acc@1: 100.0000 (97.3717)  Acc@5: 100.0000 (99.9586)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2416 (0.2389)  Acc@1: 93.7500 (96.1132)  Acc@5: 100.0000 (99.9378)\n",
            "Test: [ 250/312]  Time: 0.132 (0.141)  Loss:  0.1213 (0.2329)  Acc@1: 100.0000 (96.2276)  Acc@5: 100.0000 (99.9502)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.5122 (0.2316)  Acc@1: 90.6250 (96.4182)  Acc@5: 100.0000 (99.9481)\n",
            "Test: [ 312/312]  Time: 0.210 (0.139)  Loss:  0.1315 (0.2302)  Acc@1: 100.0000 (96.4800)  Acc@5: 100.0000 (99.9500)\n",
            "Test (EMA): [   0/312]  Time: 1.184 (1.184)  Loss:  1.4199 (1.4199)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.161)  Loss:  1.4258 (1.4704)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (99.8162)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  1.9766 (1.5856)  Acc@1: 34.3750 (89.2636)  Acc@5: 100.0000 (99.8453)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.144)  Loss:  1.6191 (1.6588)  Acc@1: 100.0000 (78.3320)  Acc@5: 100.0000 (99.7517)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  2.1484 (1.7504)  Acc@1:  0.0000 (64.1791)  Acc@5: 87.5000 (98.6007)\n",
            "Test (EMA): [ 250/312]  Time: 0.144 (0.141)  Loss:  1.9727 (1.7890)  Acc@1: 53.1250 (61.7281)  Acc@5: 100.0000 (98.5931)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  2.0957 (1.8335)  Acc@1: 43.7500 (57.2778)  Acc@5: 65.6250 (98.2454)\n",
            "Test (EMA): [ 312/312]  Time: 0.210 (0.140)  Loss:  1.9814 (1.8381)  Acc@1: 37.5000 (57.4000)  Acc@5: 100.0000 (98.3000)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-9.pth.tar', 57.4)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-8.pth.tar', 41.78)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-7.pth.tar', 31.28)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-6.pth.tar', 19.6)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-1.pth.tar', 9.8)\n",
            "\n",
            "Train: 10 [   0/1875 (  0%)]  Loss:  0.979932 (0.9799)  Time: 2.367s,   13.52/s  (2.367s,   13.52/s)  LR: 1.000e-05  Data: 1.348 (1.348)\n",
            "Train: 10 [  50/1875 (  3%)]  Loss:  2.026073 (1.7682)  Time: 0.432s,   74.00/s  (0.471s,   67.95/s)  LR: 1.000e-05  Data: 0.004 (0.031)\n",
            "Train: 10 [ 100/1875 (  5%)]  Loss:  2.030197 (1.6590)  Time: 0.432s,   74.16/s  (0.451s,   70.90/s)  LR: 1.000e-05  Data: 0.004 (0.018)\n",
            "Train: 10 [ 150/1875 (  8%)]  Loss:  2.090621 (1.6713)  Time: 0.430s,   74.34/s  (0.445s,   71.94/s)  LR: 1.000e-05  Data: 0.004 (0.013)\n",
            "Train: 10 [ 200/1875 ( 11%)]  Loss:  1.754002 (1.7122)  Time: 0.437s,   73.28/s  (0.441s,   72.51/s)  LR: 1.000e-05  Data: 0.009 (0.011)\n",
            "Train: 10 [ 250/1875 ( 13%)]  Loss:  1.199031 (1.7317)  Time: 0.431s,   74.29/s  (0.439s,   72.86/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 10 [ 300/1875 ( 16%)]  Loss:  1.094735 (1.7329)  Time: 0.431s,   74.24/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.005 (0.009)\n",
            "Train: 10 [ 350/1875 ( 19%)]  Loss:  1.223038 (1.7111)  Time: 0.431s,   74.19/s  (0.437s,   73.24/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 10 [ 400/1875 ( 21%)]  Loss:  1.903486 (1.7017)  Time: 0.431s,   74.22/s  (0.436s,   73.33/s)  LR: 1.000e-05  Data: 0.005 (0.008)\n",
            "Train: 10 [ 450/1875 ( 24%)]  Loss:  1.067979 (1.6952)  Time: 0.430s,   74.39/s  (0.436s,   73.42/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 500/1875 ( 27%)]  Loss:  1.491946 (1.6955)  Time: 0.430s,   74.42/s  (0.435s,   73.50/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 550/1875 ( 29%)]  Loss:  2.224682 (1.7173)  Time: 0.431s,   74.26/s  (0.435s,   73.54/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 600/1875 ( 32%)]  Loss:  1.598866 (1.7339)  Time: 0.431s,   74.31/s  (0.435s,   73.59/s)  LR: 1.000e-05  Data: 0.005 (0.007)\n",
            "Train: 10 [ 650/1875 ( 35%)]  Loss:  1.375104 (1.7114)  Time: 0.430s,   74.42/s  (0.435s,   73.64/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 700/1875 ( 37%)]  Loss:  1.597887 (1.6997)  Time: 0.430s,   74.35/s  (0.434s,   73.67/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 750/1875 ( 40%)]  Loss:  1.111704 (1.6940)  Time: 0.430s,   74.34/s  (0.434s,   73.70/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 800/1875 ( 43%)]  Loss:  1.926762 (1.7079)  Time: 0.432s,   74.12/s  (0.434s,   73.73/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 850/1875 ( 45%)]  Loss:  2.041463 (1.7049)  Time: 0.430s,   74.38/s  (0.434s,   73.76/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 10 [ 900/1875 ( 48%)]  Loss:  2.093826 (1.7143)  Time: 0.431s,   74.20/s  (0.434s,   73.78/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 950/1875 ( 51%)]  Loss:  1.761683 (1.7222)  Time: 0.432s,   74.08/s  (0.434s,   73.80/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1000/1875 ( 53%)]  Loss:  1.252222 (1.7167)  Time: 0.440s,   72.80/s  (0.434s,   73.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1050/1875 ( 56%)]  Loss:  1.484513 (1.7085)  Time: 0.430s,   74.44/s  (0.433s,   73.83/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1100/1875 ( 59%)]  Loss:  1.317823 (1.7007)  Time: 0.431s,   74.17/s  (0.433s,   73.84/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1150/1875 ( 61%)]  Loss:  1.323894 (1.6960)  Time: 0.431s,   74.23/s  (0.433s,   73.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1200/1875 ( 64%)]  Loss:  1.839336 (1.6990)  Time: 0.432s,   74.12/s  (0.433s,   73.87/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1250/1875 ( 67%)]  Loss:  1.374685 (1.6963)  Time: 0.440s,   72.76/s  (0.433s,   73.88/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1300/1875 ( 69%)]  Loss:  1.994967 (1.6981)  Time: 0.438s,   73.13/s  (0.433s,   73.89/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1350/1875 ( 72%)]  Loss:  2.180015 (1.6951)  Time: 0.431s,   74.32/s  (0.433s,   73.90/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 10 [1400/1875 ( 75%)]  Loss:  1.938843 (1.6954)  Time: 0.432s,   74.12/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1450/1875 ( 77%)]  Loss:  1.777544 (1.6984)  Time: 0.430s,   74.38/s  (0.433s,   73.91/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1500/1875 ( 80%)]  Loss:  1.284392 (1.6914)  Time: 0.430s,   74.40/s  (0.433s,   73.92/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1550/1875 ( 83%)]  Loss:  1.211538 (1.6887)  Time: 0.430s,   74.39/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1600/1875 ( 85%)]  Loss:  2.201681 (1.6903)  Time: 0.436s,   73.45/s  (0.433s,   73.93/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 10 [1650/1875 ( 88%)]  Loss:  2.147140 (1.6883)  Time: 0.432s,   74.06/s  (0.433s,   73.94/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1700/1875 ( 91%)]  Loss:  1.089360 (1.6847)  Time: 0.430s,   74.50/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1750/1875 ( 93%)]  Loss:  1.984310 (1.6882)  Time: 0.439s,   72.91/s  (0.433s,   73.95/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1800/1875 ( 96%)]  Loss:  2.205739 (1.6903)  Time: 0.434s,   73.71/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1850/1875 ( 99%)]  Loss:  1.300548 (1.6870)  Time: 0.430s,   74.36/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 10 [1874/1875 (100%)]  Loss:  1.391265 (1.6856)  Time: 0.568s,   56.38/s  (0.433s,   73.96/s)  LR: 1.000e-05  Data: 0.145 (0.005)\n",
            "Test: [   0/312]  Time: 1.157 (1.157)  Loss:  0.1335 (0.1335)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.161)  Loss:  0.0903 (0.1580)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.137 (0.149)  Loss:  0.2372 (0.1965)  Acc@1: 96.8750 (97.7413)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1112 (0.2117)  Acc@1: 100.0000 (97.3717)  Acc@5: 100.0000 (99.9379)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2181 (0.2384)  Acc@1: 96.8750 (96.3308)  Acc@5: 100.0000 (99.8912)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1282 (0.2350)  Acc@1: 100.0000 (96.4766)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4612 (0.2322)  Acc@1: 90.6250 (96.6881)  Acc@5: 100.0000 (99.9066)\n",
            "Test: [ 312/312]  Time: 0.209 (0.140)  Loss:  0.1476 (0.2313)  Acc@1: 100.0000 (96.7300)  Acc@5: 100.0000 (99.9100)\n",
            "Test (EMA): [   0/312]  Time: 1.161 (1.161)  Loss:  1.2285 (1.2285)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.143 (0.161)  Loss:  1.2197 (1.2864)  Acc@1: 100.0000 (98.5907)  Acc@5: 100.0000 (99.6936)\n",
            "Test (EMA): [ 100/312]  Time: 0.138 (0.148)  Loss:  1.7568 (1.4163)  Acc@1: 84.3750 (93.5953)  Acc@5: 100.0000 (99.7834)\n",
            "Test (EMA): [ 150/312]  Time: 0.134 (0.144)  Loss:  1.4316 (1.4758)  Acc@1: 100.0000 (90.4387)  Acc@5: 100.0000 (99.8344)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  1.9980 (1.5710)  Acc@1: 28.1250 (77.3321)  Acc@5: 90.6250 (99.3315)\n",
            "Test (EMA): [ 250/312]  Time: 0.138 (0.140)  Loss:  1.7920 (1.6132)  Acc@1: 84.3750 (75.6848)  Acc@5: 100.0000 (99.1658)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  1.9893 (1.6567)  Acc@1: 56.2500 (74.6678)  Acc@5: 71.8750 (98.9203)\n",
            "Test (EMA): [ 312/312]  Time: 0.206 (0.139)  Loss:  1.8203 (1.6614)  Acc@1: 81.2500 (75.1000)  Acc@5: 100.0000 (98.9500)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-10.pth.tar', 75.1)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-9.pth.tar', 57.4)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-8.pth.tar', 41.78)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-7.pth.tar', 31.28)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-6.pth.tar', 19.6)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-5.pth.tar', 11.61)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-4.pth.tar', 10.13)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-3.pth.tar', 9.94)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-0.pth.tar', 9.91)\n",
            " ('./output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-2.pth.tar', 9.91)\n",
            "\n",
            "*** Best metric: 75.1 (epoch 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15NoYt8oI5mH"
      },
      "source": [
        "ckpt = '/content/T2T-ViT/output/train/20210204-051046-T2t_vit_t_14-224/checkpoint-10.pth.tar'\r\n",
        "!cp \"$ckpt\" /content/drive/MyDrive"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2CXaHmmJI3n",
        "outputId": "750ac4a8-c960-4706-bc01-ab29a5c239ba"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/T2T-ViT')\r\n",
        "\r\n",
        "PATH_TO_DATA = '/content/data'\r\n",
        "PATH_TO_CHECKPOINT = '/content/drive/MyDrive/checkpoint-10.pth.tar'\r\n",
        "\r\n",
        "!bash distributed_train.sh 1 \"$PATH_TO_DATA\"\\\r\n",
        "    --model T2t_vit_t_14\\\r\n",
        "    --initial-checkpoint \"$PATH_TO_CHECKPOINT\"\\\r\n",
        "    --batch-size 32\\\r\n",
        "    --num-classes 10\\\r\n",
        "    --img-size 224\\\r\n",
        "    --mean 34.515\\\r\n",
        "    --std 73.506\\\r\n",
        "    --lr 1e-4\\\r\n",
        "    --epochs 1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with a single process on 1 GPUs.\n",
            "adopt transformer encoder for tokens-to-token\n",
            "Loaded state_dict from checkpoint '/content/drive/MyDrive/checkpoint-10.pth.tar'\n",
            "Model T2t_vit_t_14 created, param count: 21159920\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 224, 224)\n",
            "\tinterpolation: bicubic\n",
            "\tmean: (34.515, 34.515, 34.515)\n",
            "\tstd: (73.506, 73.506, 73.506)\n",
            "\tcrop_pct: 0.9\n",
            "Using native Torch AMP. Training in mixed precision.\n",
            "Scheduled epochs: 11\n",
            "Train: 0 [   0/1875 (  0%)]  Loss:  2.122509 (2.1225)  Time: 2.443s,   13.10/s  (2.443s,   13.10/s)  LR: 1.000e-06  Data: 1.444 (1.444)\n",
            "Train: 0 [  50/1875 (  3%)]  Loss:  1.598894 (1.8463)  Time: 0.431s,   74.19/s  (0.473s,   67.59/s)  LR: 1.000e-06  Data: 0.004 (0.033)\n",
            "Train: 0 [ 100/1875 (  5%)]  Loss:  1.202552 (1.7073)  Time: 0.434s,   73.80/s  (0.455s,   70.40/s)  LR: 1.000e-06  Data: 0.004 (0.019)\n",
            "Train: 0 [ 150/1875 (  8%)]  Loss:  1.586034 (1.7548)  Time: 0.432s,   74.03/s  (0.447s,   71.53/s)  LR: 1.000e-06  Data: 0.004 (0.014)\n",
            "Train: 0 [ 200/1875 ( 11%)]  Loss:  1.201954 (1.7534)  Time: 0.435s,   73.61/s  (0.444s,   72.08/s)  LR: 1.000e-06  Data: 0.005 (0.011)\n",
            "Train: 0 [ 250/1875 ( 13%)]  Loss:  2.026162 (1.7173)  Time: 0.434s,   73.75/s  (0.442s,   72.39/s)  LR: 1.000e-06  Data: 0.004 (0.010)\n",
            "Train: 0 [ 300/1875 ( 16%)]  Loss:  2.069047 (1.7224)  Time: 0.432s,   74.00/s  (0.441s,   72.56/s)  LR: 1.000e-06  Data: 0.004 (0.009)\n",
            "Train: 0 [ 350/1875 ( 19%)]  Loss:  2.007756 (1.7213)  Time: 0.432s,   74.04/s  (0.440s,   72.71/s)  LR: 1.000e-06  Data: 0.004 (0.008)\n",
            "Train: 0 [ 400/1875 ( 21%)]  Loss:  1.942436 (1.6821)  Time: 0.435s,   73.58/s  (0.439s,   72.81/s)  LR: 1.000e-06  Data: 0.004 (0.008)\n",
            "Train: 0 [ 450/1875 ( 24%)]  Loss:  2.162768 (1.6814)  Time: 0.438s,   73.09/s  (0.439s,   72.88/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 500/1875 ( 27%)]  Loss:  1.342197 (1.6809)  Time: 0.435s,   73.56/s  (0.439s,   72.94/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 550/1875 ( 29%)]  Loss:  0.885235 (1.6595)  Time: 0.434s,   73.80/s  (0.438s,   73.00/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 600/1875 ( 32%)]  Loss:  1.090248 (1.6650)  Time: 0.433s,   73.86/s  (0.438s,   73.04/s)  LR: 1.000e-06  Data: 0.004 (0.007)\n",
            "Train: 0 [ 650/1875 ( 35%)]  Loss:  2.014796 (1.6562)  Time: 0.435s,   73.49/s  (0.438s,   73.07/s)  LR: 1.000e-06  Data: 0.005 (0.006)\n",
            "Train: 0 [ 700/1875 ( 37%)]  Loss:  1.092649 (1.6525)  Time: 0.434s,   73.82/s  (0.438s,   73.09/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 750/1875 ( 40%)]  Loss:  1.394415 (1.6212)  Time: 0.434s,   73.75/s  (0.438s,   73.11/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 800/1875 ( 43%)]  Loss:  1.478275 (1.6359)  Time: 0.437s,   73.27/s  (0.438s,   73.13/s)  LR: 1.000e-06  Data: 0.005 (0.006)\n",
            "Train: 0 [ 850/1875 ( 45%)]  Loss:  1.732926 (1.6268)  Time: 0.442s,   72.34/s  (0.437s,   73.14/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [ 900/1875 ( 48%)]  Loss:  1.860478 (1.6271)  Time: 0.435s,   73.63/s  (0.437s,   73.15/s)  LR: 1.000e-06  Data: 0.005 (0.006)\n",
            "Train: 0 [ 950/1875 ( 51%)]  Loss:  0.936391 (1.6340)  Time: 0.435s,   73.53/s  (0.437s,   73.16/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1000/1875 ( 53%)]  Loss:  1.174933 (1.6321)  Time: 0.436s,   73.37/s  (0.437s,   73.18/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1050/1875 ( 56%)]  Loss:  1.871974 (1.6228)  Time: 0.436s,   73.46/s  (0.437s,   73.19/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1100/1875 ( 59%)]  Loss:  1.361762 (1.6245)  Time: 0.433s,   73.91/s  (0.437s,   73.20/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1150/1875 ( 61%)]  Loss:  1.909051 (1.6320)  Time: 0.438s,   72.98/s  (0.437s,   73.20/s)  LR: 1.000e-06  Data: 0.004 (0.006)\n",
            "Train: 0 [1200/1875 ( 64%)]  Loss:  1.268603 (1.6368)  Time: 0.443s,   72.18/s  (0.437s,   73.21/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1250/1875 ( 67%)]  Loss:  1.554588 (1.6290)  Time: 0.435s,   73.57/s  (0.437s,   73.21/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1300/1875 ( 69%)]  Loss:  1.221593 (1.6229)  Time: 0.433s,   73.86/s  (0.437s,   73.22/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1350/1875 ( 72%)]  Loss:  2.054492 (1.6327)  Time: 0.437s,   73.26/s  (0.437s,   73.23/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1400/1875 ( 75%)]  Loss:  1.122961 (1.6321)  Time: 0.438s,   73.14/s  (0.437s,   73.24/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1450/1875 ( 77%)]  Loss:  2.069032 (1.6231)  Time: 0.435s,   73.56/s  (0.437s,   73.24/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1500/1875 ( 80%)]  Loss:  1.160586 (1.6220)  Time: 0.435s,   73.64/s  (0.437s,   73.25/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1550/1875 ( 83%)]  Loss:  1.637957 (1.6189)  Time: 0.445s,   71.93/s  (0.437s,   73.25/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1600/1875 ( 85%)]  Loss:  2.020827 (1.6224)  Time: 0.435s,   73.48/s  (0.437s,   73.26/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1650/1875 ( 88%)]  Loss:  1.576665 (1.6215)  Time: 0.434s,   73.69/s  (0.437s,   73.26/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1700/1875 ( 91%)]  Loss:  2.039622 (1.6235)  Time: 0.435s,   73.54/s  (0.437s,   73.26/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1750/1875 ( 93%)]  Loss:  2.013370 (1.6330)  Time: 0.433s,   73.92/s  (0.437s,   73.27/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1800/1875 ( 96%)]  Loss:  2.057247 (1.6333)  Time: 0.433s,   73.86/s  (0.437s,   73.27/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1850/1875 ( 99%)]  Loss:  2.116224 (1.6314)  Time: 0.433s,   73.91/s  (0.437s,   73.27/s)  LR: 1.000e-06  Data: 0.004 (0.005)\n",
            "Train: 0 [1874/1875 (100%)]  Loss:  1.054488 (1.6285)  Time: 0.575s,   55.66/s  (0.437s,   73.27/s)  LR: 1.000e-06  Data: 0.150 (0.005)\n",
            "Test: [   0/312]  Time: 1.183 (1.183)  Loss:  0.1211 (0.1211)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.138 (0.162)  Loss:  0.1025 (0.1506)  Acc@1: 100.0000 (99.1422)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.138 (0.149)  Loss:  0.2139 (0.1787)  Acc@1: 96.8750 (98.2983)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.138 (0.144)  Loss:  0.1322 (0.1965)  Acc@1: 100.0000 (97.8684)  Acc@5: 100.0000 (99.9586)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2256 (0.2325)  Acc@1: 96.8750 (96.5174)  Acc@5: 100.0000 (99.8912)\n",
            "Test: [ 250/312]  Time: 0.140 (0.141)  Loss:  0.1440 (0.2356)  Acc@1: 100.0000 (96.5513)  Acc@5: 100.0000 (99.9128)\n",
            "Test: [ 300/312]  Time: 0.131 (0.140)  Loss:  0.4678 (0.2341)  Acc@1: 87.5000 (96.6985)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 312/312]  Time: 0.217 (0.140)  Loss:  0.1355 (0.2326)  Acc@1: 100.0000 (96.7400)  Acc@5: 100.0000 (99.9200)\n",
            "Test (EMA): [   0/312]  Time: 1.285 (1.285)  Loss:  0.1323 (0.1323)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.163)  Loss:  0.0908 (0.1571)  Acc@1: 100.0000 (99.0809)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.137 (0.150)  Loss:  0.2349 (0.1949)  Acc@1: 96.8750 (97.8032)  Acc@5: 100.0000 (99.9691)\n",
            "Test (EMA): [ 150/312]  Time: 0.135 (0.145)  Loss:  0.1119 (0.2103)  Acc@1: 100.0000 (97.4131)  Acc@5: 100.0000 (99.9379)\n",
            "Test (EMA): [ 200/312]  Time: 0.143 (0.142)  Loss:  0.2175 (0.2376)  Acc@1: 96.8750 (96.3464)  Acc@5: 100.0000 (99.8912)\n",
            "Test (EMA): [ 250/312]  Time: 0.144 (0.141)  Loss:  0.1293 (0.2345)  Acc@1: 100.0000 (96.4890)  Acc@5: 100.0000 (99.9004)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4592 (0.2319)  Acc@1: 90.6250 (96.7089)  Acc@5: 100.0000 (99.9066)\n",
            "Test (EMA): [ 312/312]  Time: 0.217 (0.140)  Loss:  0.1465 (0.2310)  Acc@1: 100.0000 (96.7500)  Acc@5: 100.0000 (99.9100)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            "\n",
            "Train: 1 [   0/1875 (  0%)]  Loss:  1.941526 (1.9415)  Time: 2.416s,   13.24/s  (2.416s,   13.24/s)  LR: 3.400e-05  Data: 1.549 (1.549)\n",
            "Train: 1 [  50/1875 (  3%)]  Loss:  1.368853 (1.8487)  Time: 0.434s,   73.75/s  (0.476s,   67.28/s)  LR: 3.400e-05  Data: 0.004 (0.035)\n",
            "Train: 1 [ 100/1875 (  5%)]  Loss:  1.215040 (1.7196)  Time: 0.436s,   73.47/s  (0.456s,   70.17/s)  LR: 3.400e-05  Data: 0.004 (0.020)\n",
            "Train: 1 [ 150/1875 (  8%)]  Loss:  1.370779 (1.7705)  Time: 0.437s,   73.26/s  (0.449s,   71.25/s)  LR: 3.400e-05  Data: 0.004 (0.015)\n",
            "Train: 1 [ 200/1875 ( 11%)]  Loss:  1.374792 (1.7768)  Time: 0.442s,   72.46/s  (0.446s,   71.76/s)  LR: 3.400e-05  Data: 0.004 (0.012)\n",
            "Train: 1 [ 250/1875 ( 13%)]  Loss:  1.970212 (1.7476)  Time: 0.437s,   73.29/s  (0.444s,   72.06/s)  LR: 3.400e-05  Data: 0.004 (0.010)\n",
            "Train: 1 [ 300/1875 ( 16%)]  Loss:  2.106397 (1.7528)  Time: 0.432s,   74.01/s  (0.443s,   72.27/s)  LR: 3.400e-05  Data: 0.004 (0.009)\n",
            "Train: 1 [ 350/1875 ( 19%)]  Loss:  1.907089 (1.7542)  Time: 0.436s,   73.45/s  (0.442s,   72.43/s)  LR: 3.400e-05  Data: 0.004 (0.009)\n",
            "Train: 1 [ 400/1875 ( 21%)]  Loss:  2.038745 (1.7121)  Time: 0.436s,   73.44/s  (0.441s,   72.55/s)  LR: 3.400e-05  Data: 0.004 (0.008)\n",
            "Train: 1 [ 450/1875 ( 24%)]  Loss:  2.069487 (1.7144)  Time: 0.434s,   73.70/s  (0.441s,   72.64/s)  LR: 3.400e-05  Data: 0.004 (0.008)\n",
            "Train: 1 [ 500/1875 ( 27%)]  Loss:  1.429344 (1.7168)  Time: 0.435s,   73.55/s  (0.440s,   72.71/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 550/1875 ( 29%)]  Loss:  1.130684 (1.6988)  Time: 0.441s,   72.50/s  (0.440s,   72.75/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 600/1875 ( 32%)]  Loss:  1.359379 (1.7027)  Time: 0.435s,   73.63/s  (0.440s,   72.80/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 650/1875 ( 35%)]  Loss:  2.066383 (1.6958)  Time: 0.436s,   73.46/s  (0.439s,   72.85/s)  LR: 3.400e-05  Data: 0.004 (0.007)\n",
            "Train: 1 [ 700/1875 ( 37%)]  Loss:  1.514211 (1.6951)  Time: 0.433s,   73.83/s  (0.439s,   72.89/s)  LR: 3.400e-05  Data: 0.005 (0.007)\n",
            "Train: 1 [ 750/1875 ( 40%)]  Loss:  1.026410 (1.6651)  Time: 0.435s,   73.57/s  (0.439s,   72.91/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 800/1875 ( 43%)]  Loss:  1.771127 (1.6804)  Time: 0.436s,   73.44/s  (0.439s,   72.94/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 850/1875 ( 45%)]  Loss:  1.887883 (1.6733)  Time: 0.435s,   73.63/s  (0.439s,   72.96/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 900/1875 ( 48%)]  Loss:  1.755971 (1.6740)  Time: 0.442s,   72.33/s  (0.438s,   72.99/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [ 950/1875 ( 51%)]  Loss:  1.281495 (1.6785)  Time: 0.434s,   73.67/s  (0.438s,   73.01/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1000/1875 ( 53%)]  Loss:  1.277449 (1.6772)  Time: 0.435s,   73.56/s  (0.438s,   73.02/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1050/1875 ( 56%)]  Loss:  2.131282 (1.6681)  Time: 0.436s,   73.40/s  (0.438s,   73.04/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1100/1875 ( 59%)]  Loss:  1.271538 (1.6693)  Time: 0.436s,   73.46/s  (0.438s,   73.06/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1150/1875 ( 61%)]  Loss:  1.692996 (1.6783)  Time: 0.434s,   73.69/s  (0.438s,   73.07/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1200/1875 ( 64%)]  Loss:  1.265677 (1.6846)  Time: 0.436s,   73.39/s  (0.438s,   73.08/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1250/1875 ( 67%)]  Loss:  1.541908 (1.6763)  Time: 0.435s,   73.49/s  (0.438s,   73.09/s)  LR: 3.400e-05  Data: 0.005 (0.006)\n",
            "Train: 1 [1300/1875 ( 69%)]  Loss:  1.162386 (1.6691)  Time: 0.436s,   73.36/s  (0.438s,   73.10/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1350/1875 ( 72%)]  Loss:  2.019407 (1.6798)  Time: 0.435s,   73.59/s  (0.438s,   73.11/s)  LR: 3.400e-05  Data: 0.004 (0.006)\n",
            "Train: 1 [1400/1875 ( 75%)]  Loss:  1.265080 (1.6803)  Time: 0.433s,   73.85/s  (0.438s,   73.13/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1450/1875 ( 77%)]  Loss:  2.050533 (1.6723)  Time: 0.436s,   73.34/s  (0.438s,   73.14/s)  LR: 3.400e-05  Data: 0.005 (0.005)\n",
            "Train: 1 [1500/1875 ( 80%)]  Loss:  1.084239 (1.6716)  Time: 0.446s,   71.82/s  (0.437s,   73.15/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1550/1875 ( 83%)]  Loss:  1.615752 (1.6688)  Time: 0.436s,   73.31/s  (0.437s,   73.15/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1600/1875 ( 85%)]  Loss:  2.039750 (1.6725)  Time: 0.433s,   73.92/s  (0.437s,   73.16/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1650/1875 ( 88%)]  Loss:  1.497757 (1.6714)  Time: 0.439s,   72.90/s  (0.437s,   73.16/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1700/1875 ( 91%)]  Loss:  2.198943 (1.6720)  Time: 0.434s,   73.78/s  (0.437s,   73.17/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1750/1875 ( 93%)]  Loss:  2.100213 (1.6817)  Time: 0.433s,   73.87/s  (0.437s,   73.18/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1800/1875 ( 96%)]  Loss:  2.112888 (1.6817)  Time: 0.435s,   73.54/s  (0.437s,   73.19/s)  LR: 3.400e-05  Data: 0.004 (0.005)\n",
            "Train: 1 [1850/1875 ( 99%)]  Loss:  2.036840 (1.6798)  Time: 0.433s,   73.86/s  (0.437s,   73.19/s)  LR: 3.400e-05  Data: 0.005 (0.005)\n",
            "Train: 1 [1874/1875 (100%)]  Loss:  1.363044 (1.6768)  Time: 0.592s,   54.03/s  (0.437s,   73.18/s)  LR: 3.400e-05  Data: 0.164 (0.005)\n",
            "Test: [   0/312]  Time: 1.208 (1.208)  Loss:  0.1593 (0.1593)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.138 (0.161)  Loss:  0.0997 (0.1714)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.149)  Loss:  0.2742 (0.1918)  Acc@1: 96.8750 (97.4938)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.132 (0.145)  Loss:  0.1125 (0.2113)  Acc@1: 100.0000 (96.9785)  Acc@5: 100.0000 (99.9379)\n",
            "Test: [ 200/312]  Time: 0.131 (0.143)  Loss:  0.2590 (0.2528)  Acc@1: 96.8750 (95.6468)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.0951 (0.2368)  Acc@1: 100.0000 (96.0657)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/312]  Time: 0.131 (0.140)  Loss:  0.4253 (0.2329)  Acc@1: 90.6250 (96.2521)  Acc@5: 100.0000 (99.9066)\n",
            "Test: [ 312/312]  Time: 0.214 (0.140)  Loss:  0.1418 (0.2316)  Acc@1: 100.0000 (96.3300)  Acc@5: 100.0000 (99.9100)\n",
            "Test (EMA): [   0/312]  Time: 1.148 (1.148)  Loss:  0.1306 (0.1306)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.137 (0.161)  Loss:  0.0908 (0.1552)  Acc@1: 100.0000 (99.1422)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.132 (0.149)  Loss:  0.2313 (0.1916)  Acc@1: 96.8750 (97.8651)  Acc@5: 100.0000 (99.9691)\n",
            "Test (EMA): [ 150/312]  Time: 0.143 (0.144)  Loss:  0.1125 (0.2073)  Acc@1: 100.0000 (97.4752)  Acc@5: 100.0000 (99.9379)\n",
            "Test (EMA): [ 200/312]  Time: 0.141 (0.143)  Loss:  0.2156 (0.2346)  Acc@1: 96.8750 (96.3930)  Acc@5: 100.0000 (99.9067)\n",
            "Test (EMA): [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1273 (0.2322)  Acc@1: 100.0000 (96.5139)  Acc@5: 100.0000 (99.9128)\n",
            "Test (EMA): [ 300/312]  Time: 0.131 (0.140)  Loss:  0.4583 (0.2297)  Acc@1: 90.6250 (96.7193)  Acc@5: 100.0000 (99.9169)\n",
            "Test (EMA): [ 312/312]  Time: 0.214 (0.140)  Loss:  0.1425 (0.2287)  Acc@1: 100.0000 (96.7600)  Acc@5: 100.0000 (99.9200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            "\n",
            "Train: 2 [   0/1875 (  0%)]  Loss:  2.017053 (2.0171)  Time: 2.398s,   13.35/s  (2.398s,   13.35/s)  LR: 6.700e-05  Data: 1.612 (1.612)\n",
            "Train: 2 [  50/1875 (  3%)]  Loss:  1.256630 (1.8631)  Time: 0.435s,   73.62/s  (0.475s,   67.33/s)  LR: 6.700e-05  Data: 0.004 (0.036)\n",
            "Train: 2 [ 100/1875 (  5%)]  Loss:  1.203388 (1.7676)  Time: 0.436s,   73.36/s  (0.456s,   70.25/s)  LR: 6.700e-05  Data: 0.004 (0.020)\n",
            "Train: 2 [ 150/1875 (  8%)]  Loss:  1.194528 (1.8080)  Time: 0.433s,   73.87/s  (0.449s,   71.28/s)  LR: 6.700e-05  Data: 0.004 (0.015)\n",
            "Train: 2 [ 200/1875 ( 11%)]  Loss:  1.523329 (1.8107)  Time: 0.433s,   73.98/s  (0.446s,   71.78/s)  LR: 6.700e-05  Data: 0.004 (0.012)\n",
            "Train: 2 [ 250/1875 ( 13%)]  Loss:  1.836534 (1.7826)  Time: 0.435s,   73.62/s  (0.444s,   72.10/s)  LR: 6.700e-05  Data: 0.004 (0.011)\n",
            "Train: 2 [ 300/1875 ( 16%)]  Loss:  1.997902 (1.7872)  Time: 0.434s,   73.69/s  (0.442s,   72.33/s)  LR: 6.700e-05  Data: 0.004 (0.010)\n",
            "Train: 2 [ 350/1875 ( 19%)]  Loss:  2.112442 (1.7825)  Time: 0.435s,   73.60/s  (0.441s,   72.50/s)  LR: 6.700e-05  Data: 0.004 (0.009)\n",
            "Train: 2 [ 400/1875 ( 21%)]  Loss:  2.160665 (1.7383)  Time: 0.434s,   73.79/s  (0.441s,   72.60/s)  LR: 6.700e-05  Data: 0.004 (0.008)\n",
            "Train: 2 [ 450/1875 ( 24%)]  Loss:  2.000179 (1.7417)  Time: 0.435s,   73.57/s  (0.440s,   72.69/s)  LR: 6.700e-05  Data: 0.004 (0.008)\n",
            "Train: 2 [ 500/1875 ( 27%)]  Loss:  1.346170 (1.7392)  Time: 0.432s,   73.99/s  (0.440s,   72.76/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 550/1875 ( 29%)]  Loss:  1.229152 (1.7184)  Time: 0.435s,   73.53/s  (0.439s,   72.82/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 600/1875 ( 32%)]  Loss:  1.259501 (1.7216)  Time: 0.443s,   72.28/s  (0.439s,   72.86/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 650/1875 ( 35%)]  Loss:  2.171583 (1.7119)  Time: 0.436s,   73.46/s  (0.439s,   72.91/s)  LR: 6.700e-05  Data: 0.005 (0.007)\n",
            "Train: 2 [ 700/1875 ( 37%)]  Loss:  1.481016 (1.7121)  Time: 0.434s,   73.79/s  (0.439s,   72.95/s)  LR: 6.700e-05  Data: 0.004 (0.007)\n",
            "Train: 2 [ 750/1875 ( 40%)]  Loss:  1.148365 (1.6807)  Time: 0.435s,   73.51/s  (0.438s,   72.98/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 800/1875 ( 43%)]  Loss:  1.805660 (1.6960)  Time: 0.434s,   73.70/s  (0.438s,   73.01/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 850/1875 ( 45%)]  Loss:  1.768101 (1.6862)  Time: 0.444s,   72.10/s  (0.438s,   73.03/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 900/1875 ( 48%)]  Loss:  1.921471 (1.6871)  Time: 0.435s,   73.59/s  (0.438s,   73.05/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [ 950/1875 ( 51%)]  Loss:  1.157281 (1.6918)  Time: 0.436s,   73.33/s  (0.438s,   73.07/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1000/1875 ( 53%)]  Loss:  1.539773 (1.6902)  Time: 0.437s,   73.31/s  (0.438s,   73.09/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1050/1875 ( 56%)]  Loss:  2.242574 (1.6807)  Time: 0.436s,   73.41/s  (0.438s,   73.11/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1100/1875 ( 59%)]  Loss:  1.205378 (1.6830)  Time: 0.438s,   73.13/s  (0.438s,   73.12/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1150/1875 ( 61%)]  Loss:  1.784431 (1.6917)  Time: 0.433s,   73.87/s  (0.438s,   73.14/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1200/1875 ( 64%)]  Loss:  1.523051 (1.6971)  Time: 0.437s,   73.30/s  (0.437s,   73.15/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1250/1875 ( 67%)]  Loss:  1.717088 (1.6876)  Time: 0.435s,   73.50/s  (0.437s,   73.16/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1300/1875 ( 69%)]  Loss:  1.042844 (1.6807)  Time: 0.435s,   73.64/s  (0.437s,   73.16/s)  LR: 6.700e-05  Data: 0.004 (0.006)\n",
            "Train: 2 [1350/1875 ( 72%)]  Loss:  2.063607 (1.6910)  Time: 0.436s,   73.35/s  (0.437s,   73.17/s)  LR: 6.700e-05  Data: 0.007 (0.005)\n",
            "Train: 2 [1400/1875 ( 75%)]  Loss:  1.379946 (1.6912)  Time: 0.433s,   73.92/s  (0.437s,   73.18/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1450/1875 ( 77%)]  Loss:  2.124686 (1.6827)  Time: 0.443s,   72.16/s  (0.437s,   73.19/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1500/1875 ( 80%)]  Loss:  0.950857 (1.6807)  Time: 0.442s,   72.46/s  (0.437s,   73.19/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1550/1875 ( 83%)]  Loss:  1.417983 (1.6756)  Time: 0.433s,   73.83/s  (0.437s,   73.20/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1600/1875 ( 85%)]  Loss:  1.959811 (1.6791)  Time: 0.433s,   73.90/s  (0.437s,   73.20/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1650/1875 ( 88%)]  Loss:  1.742913 (1.6763)  Time: 0.434s,   73.79/s  (0.437s,   73.21/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1700/1875 ( 91%)]  Loss:  2.192440 (1.6770)  Time: 0.433s,   73.86/s  (0.437s,   73.22/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1750/1875 ( 93%)]  Loss:  1.990293 (1.6862)  Time: 0.434s,   73.79/s  (0.437s,   73.22/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1800/1875 ( 96%)]  Loss:  2.223124 (1.6857)  Time: 0.442s,   72.40/s  (0.437s,   73.23/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1850/1875 ( 99%)]  Loss:  2.196504 (1.6843)  Time: 0.435s,   73.48/s  (0.437s,   73.23/s)  LR: 6.700e-05  Data: 0.004 (0.005)\n",
            "Train: 2 [1874/1875 (100%)]  Loss:  1.138115 (1.6808)  Time: 0.583s,   54.86/s  (0.437s,   73.23/s)  LR: 6.700e-05  Data: 0.155 (0.005)\n",
            "Test: [   0/312]  Time: 1.219 (1.219)  Loss:  0.1683 (0.1683)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.139 (0.162)  Loss:  0.1151 (0.1993)  Acc@1: 100.0000 (97.7941)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.149)  Loss:  0.3000 (0.2442)  Acc@1: 93.7500 (96.5347)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.145 (0.145)  Loss:  0.1025 (0.2577)  Acc@1: 100.0000 (95.5091)  Acc@5: 100.0000 (99.9586)\n",
            "Test: [ 200/312]  Time: 0.137 (0.142)  Loss:  0.1870 (0.2414)  Acc@1: 96.8750 (95.9266)  Acc@5: 100.0000 (99.9378)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1814 (0.2310)  Acc@1: 100.0000 (96.4019)  Acc@5: 100.0000 (99.9502)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.3257 (0.2354)  Acc@1: 96.8750 (96.3870)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 312/312]  Time: 0.223 (0.140)  Loss:  0.0923 (0.2318)  Acc@1: 100.0000 (96.4500)  Acc@5: 100.0000 (99.9400)\n",
            "Test (EMA): [   0/312]  Time: 1.236 (1.236)  Loss:  0.1261 (0.1261)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.162)  Loss:  0.0901 (0.1510)  Acc@1: 100.0000 (99.1422)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.138 (0.149)  Loss:  0.2223 (0.1863)  Acc@1: 96.8750 (97.8960)  Acc@5: 100.0000 (99.9691)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.145)  Loss:  0.1118 (0.2016)  Acc@1: 100.0000 (97.5579)  Acc@5: 100.0000 (99.9379)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.143)  Loss:  0.2136 (0.2293)  Acc@1: 96.8750 (96.4397)  Acc@5: 100.0000 (99.9067)\n",
            "Test (EMA): [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1247 (0.2276)  Acc@1: 100.0000 (96.5388)  Acc@5: 100.0000 (99.9128)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4565 (0.2253)  Acc@1: 90.6250 (96.6985)  Acc@5: 100.0000 (99.9169)\n",
            "Test (EMA): [ 312/312]  Time: 0.219 (0.140)  Loss:  0.1346 (0.2242)  Acc@1: 100.0000 (96.7400)  Acc@5: 100.0000 (99.9200)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 3 [   0/1875 (  0%)]  Loss:  2.152034 (2.1520)  Time: 2.402s,   13.32/s  (2.402s,   13.32/s)  LR: 1.000e-05  Data: 1.573 (1.573)\n",
            "Train: 3 [  50/1875 (  3%)]  Loss:  1.092624 (1.8608)  Time: 0.434s,   73.77/s  (0.474s,   67.52/s)  LR: 1.000e-05  Data: 0.004 (0.035)\n",
            "Train: 3 [ 100/1875 (  5%)]  Loss:  1.417885 (1.7226)  Time: 0.444s,   72.04/s  (0.455s,   70.31/s)  LR: 1.000e-05  Data: 0.004 (0.020)\n",
            "Train: 3 [ 150/1875 (  8%)]  Loss:  1.286548 (1.7509)  Time: 0.433s,   73.96/s  (0.449s,   71.31/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 3 [ 200/1875 ( 11%)]  Loss:  1.518326 (1.7550)  Time: 0.435s,   73.63/s  (0.446s,   71.82/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 3 [ 250/1875 ( 13%)]  Loss:  2.019966 (1.7160)  Time: 0.433s,   73.96/s  (0.444s,   72.13/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 3 [ 300/1875 ( 16%)]  Loss:  2.119374 (1.7203)  Time: 0.434s,   73.74/s  (0.442s,   72.33/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 3 [ 350/1875 ( 19%)]  Loss:  2.106804 (1.7171)  Time: 0.438s,   73.01/s  (0.442s,   72.47/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 3 [ 400/1875 ( 21%)]  Loss:  1.856741 (1.6687)  Time: 0.433s,   73.90/s  (0.441s,   72.59/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 3 [ 450/1875 ( 24%)]  Loss:  1.925117 (1.6673)  Time: 0.435s,   73.53/s  (0.440s,   72.70/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 3 [ 500/1875 ( 27%)]  Loss:  1.138096 (1.6696)  Time: 0.434s,   73.76/s  (0.440s,   72.77/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 550/1875 ( 29%)]  Loss:  1.152734 (1.6479)  Time: 0.435s,   73.64/s  (0.439s,   72.84/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 600/1875 ( 32%)]  Loss:  1.312619 (1.6525)  Time: 0.433s,   73.94/s  (0.439s,   72.88/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 650/1875 ( 35%)]  Loss:  1.892209 (1.6424)  Time: 0.435s,   73.55/s  (0.439s,   72.91/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 3 [ 700/1875 ( 37%)]  Loss:  1.214456 (1.6412)  Time: 0.442s,   72.43/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 750/1875 ( 40%)]  Loss:  1.227661 (1.6093)  Time: 0.436s,   73.37/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 800/1875 ( 43%)]  Loss:  1.236745 (1.6233)  Time: 0.434s,   73.68/s  (0.438s,   72.99/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 3 [ 850/1875 ( 45%)]  Loss:  1.819338 (1.6120)  Time: 0.435s,   73.58/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 900/1875 ( 48%)]  Loss:  1.792589 (1.6117)  Time: 0.435s,   73.57/s  (0.438s,   73.04/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [ 950/1875 ( 51%)]  Loss:  1.145991 (1.6170)  Time: 0.436s,   73.31/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1000/1875 ( 53%)]  Loss:  1.059147 (1.6142)  Time: 0.434s,   73.80/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1050/1875 ( 56%)]  Loss:  1.939909 (1.6048)  Time: 0.449s,   71.31/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.008 (0.006)\n",
            "Train: 3 [1100/1875 ( 59%)]  Loss:  1.110970 (1.6061)  Time: 0.435s,   73.51/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1150/1875 ( 61%)]  Loss:  1.837308 (1.6145)  Time: 0.434s,   73.77/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1200/1875 ( 64%)]  Loss:  1.401405 (1.6205)  Time: 0.437s,   73.30/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 3 [1250/1875 ( 67%)]  Loss:  1.600786 (1.6129)  Time: 0.433s,   73.93/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 3 [1300/1875 ( 69%)]  Loss:  1.008646 (1.6066)  Time: 0.435s,   73.54/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1350/1875 ( 72%)]  Loss:  1.780520 (1.6173)  Time: 0.435s,   73.62/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1400/1875 ( 75%)]  Loss:  0.955122 (1.6184)  Time: 0.443s,   72.23/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1450/1875 ( 77%)]  Loss:  1.789246 (1.6101)  Time: 0.434s,   73.68/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1500/1875 ( 80%)]  Loss:  0.851538 (1.6092)  Time: 0.436s,   73.39/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1550/1875 ( 83%)]  Loss:  1.324798 (1.6052)  Time: 0.433s,   73.83/s  (0.437s,   73.17/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1600/1875 ( 85%)]  Loss:  2.113456 (1.6090)  Time: 0.433s,   73.82/s  (0.437s,   73.17/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1650/1875 ( 88%)]  Loss:  1.485981 (1.6072)  Time: 0.437s,   73.30/s  (0.437s,   73.18/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1700/1875 ( 91%)]  Loss:  1.898740 (1.6078)  Time: 0.435s,   73.61/s  (0.437s,   73.18/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1750/1875 ( 93%)]  Loss:  2.135223 (1.6188)  Time: 0.444s,   72.05/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1800/1875 ( 96%)]  Loss:  2.054337 (1.6185)  Time: 0.434s,   73.73/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 3 [1850/1875 ( 99%)]  Loss:  2.060411 (1.6155)  Time: 0.437s,   73.27/s  (0.437s,   73.20/s)  LR: 1.000e-05  Data: 0.007 (0.005)\n",
            "Train: 3 [1874/1875 (100%)]  Loss:  1.287712 (1.6125)  Time: 0.581s,   55.11/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.154 (0.005)\n",
            "Test: [   0/312]  Time: 1.250 (1.250)  Loss:  0.1367 (0.1367)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.140 (0.161)  Loss:  0.0970 (0.1566)  Acc@1: 100.0000 (99.0809)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.137 (0.148)  Loss:  0.2434 (0.1827)  Acc@1: 96.8750 (98.0198)  Acc@5: 100.0000 (99.9381)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1175 (0.1948)  Acc@1: 100.0000 (97.5166)  Acc@5: 100.0000 (99.8965)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1902 (0.2079)  Acc@1: 96.8750 (97.1549)  Acc@5: 100.0000 (99.9067)\n",
            "Test: [ 250/312]  Time: 0.132 (0.141)  Loss:  0.1234 (0.2123)  Acc@1: 100.0000 (97.0493)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4036 (0.2111)  Acc@1: 90.6250 (97.1761)  Acc@5: 100.0000 (99.9066)\n",
            "Test: [ 312/312]  Time: 0.222 (0.140)  Loss:  0.1044 (0.2088)  Acc@1: 100.0000 (97.2600)  Acc@5: 100.0000 (99.9100)\n",
            "Test (EMA): [   0/312]  Time: 1.225 (1.225)  Loss:  0.1217 (0.1217)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.140 (0.161)  Loss:  0.0884 (0.1459)  Acc@1: 100.0000 (99.2034)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.132 (0.148)  Loss:  0.2144 (0.1805)  Acc@1: 96.8750 (98.0198)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.145 (0.144)  Loss:  0.1118 (0.1957)  Acc@1: 100.0000 (97.7235)  Acc@5: 100.0000 (99.9586)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2100 (0.2233)  Acc@1: 96.8750 (96.6418)  Acc@5: 100.0000 (99.9223)\n",
            "Test (EMA): [ 250/312]  Time: 0.132 (0.141)  Loss:  0.1241 (0.2228)  Acc@1: 100.0000 (96.7007)  Acc@5: 100.0000 (99.9253)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4504 (0.2211)  Acc@1: 90.6250 (96.8231)  Acc@5: 100.0000 (99.9273)\n",
            "Test (EMA): [ 312/312]  Time: 0.215 (0.140)  Loss:  0.1290 (0.2200)  Acc@1: 100.0000 (96.8600)  Acc@5: 100.0000 (99.9300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 4 [   0/1875 (  0%)]  Loss:  2.021924 (2.0219)  Time: 2.372s,   13.49/s  (2.372s,   13.49/s)  LR: 1.000e-05  Data: 1.462 (1.462)\n",
            "Train: 4 [  50/1875 (  3%)]  Loss:  1.219084 (1.8212)  Time: 0.434s,   73.81/s  (0.476s,   67.25/s)  LR: 1.000e-05  Data: 0.004 (0.033)\n",
            "Train: 4 [ 100/1875 (  5%)]  Loss:  1.178142 (1.6790)  Time: 0.434s,   73.73/s  (0.456s,   70.19/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 4 [ 150/1875 (  8%)]  Loss:  1.134683 (1.7204)  Time: 0.437s,   73.25/s  (0.449s,   71.20/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 4 [ 200/1875 ( 11%)]  Loss:  1.424294 (1.7220)  Time: 0.435s,   73.55/s  (0.446s,   71.70/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 4 [ 250/1875 ( 13%)]  Loss:  1.916932 (1.6918)  Time: 0.435s,   73.65/s  (0.444s,   72.02/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 4 [ 300/1875 ( 16%)]  Loss:  1.985770 (1.6994)  Time: 0.435s,   73.57/s  (0.443s,   72.24/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 4 [ 350/1875 ( 19%)]  Loss:  2.043748 (1.6987)  Time: 0.436s,   73.42/s  (0.442s,   72.41/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 400/1875 ( 21%)]  Loss:  2.055474 (1.6512)  Time: 0.435s,   73.54/s  (0.441s,   72.52/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 450/1875 ( 24%)]  Loss:  2.138181 (1.6518)  Time: 0.434s,   73.69/s  (0.441s,   72.60/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 4 [ 500/1875 ( 27%)]  Loss:  1.440609 (1.6510)  Time: 0.437s,   73.24/s  (0.440s,   72.68/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 550/1875 ( 29%)]  Loss:  1.350666 (1.6289)  Time: 0.435s,   73.56/s  (0.440s,   72.74/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 600/1875 ( 32%)]  Loss:  1.236519 (1.6342)  Time: 0.436s,   73.47/s  (0.440s,   72.79/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 650/1875 ( 35%)]  Loss:  1.895777 (1.6236)  Time: 0.439s,   72.91/s  (0.439s,   72.83/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 4 [ 700/1875 ( 37%)]  Loss:  1.398288 (1.6222)  Time: 0.434s,   73.66/s  (0.439s,   72.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 750/1875 ( 40%)]  Loss:  0.872456 (1.5896)  Time: 0.435s,   73.56/s  (0.439s,   72.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 800/1875 ( 43%)]  Loss:  1.385401 (1.6045)  Time: 0.438s,   72.98/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 850/1875 ( 45%)]  Loss:  1.593179 (1.5935)  Time: 0.436s,   73.45/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 900/1875 ( 48%)]  Loss:  1.652766 (1.5912)  Time: 0.434s,   73.78/s  (0.439s,   72.96/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [ 950/1875 ( 51%)]  Loss:  1.216984 (1.5959)  Time: 0.435s,   73.58/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1000/1875 ( 53%)]  Loss:  1.201644 (1.5949)  Time: 0.441s,   72.50/s  (0.438s,   73.00/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1050/1875 ( 56%)]  Loss:  1.831403 (1.5837)  Time: 0.442s,   72.32/s  (0.438s,   73.01/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1100/1875 ( 59%)]  Loss:  0.952760 (1.5844)  Time: 0.434s,   73.75/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1150/1875 ( 61%)]  Loss:  1.764457 (1.5914)  Time: 0.434s,   73.73/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1200/1875 ( 64%)]  Loss:  1.247264 (1.5972)  Time: 0.434s,   73.72/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1250/1875 ( 67%)]  Loss:  1.362475 (1.5892)  Time: 0.434s,   73.73/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 4 [1300/1875 ( 69%)]  Loss:  0.962223 (1.5832)  Time: 0.433s,   73.87/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 4 [1350/1875 ( 72%)]  Loss:  2.274454 (1.5944)  Time: 0.441s,   72.53/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1400/1875 ( 75%)]  Loss:  1.217123 (1.5948)  Time: 0.432s,   73.99/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1450/1875 ( 77%)]  Loss:  1.929755 (1.5866)  Time: 0.432s,   74.08/s  (0.437s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1500/1875 ( 80%)]  Loss:  1.140632 (1.5864)  Time: 0.432s,   74.12/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1550/1875 ( 83%)]  Loss:  1.331367 (1.5809)  Time: 0.437s,   73.18/s  (0.437s,   73.18/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 4 [1600/1875 ( 85%)]  Loss:  1.992220 (1.5847)  Time: 0.434s,   73.74/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1650/1875 ( 88%)]  Loss:  1.630052 (1.5830)  Time: 0.445s,   71.90/s  (0.437s,   73.20/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1700/1875 ( 91%)]  Loss:  2.106720 (1.5831)  Time: 0.434s,   73.76/s  (0.437s,   73.20/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1750/1875 ( 93%)]  Loss:  2.009430 (1.5937)  Time: 0.436s,   73.39/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 4 [1800/1875 ( 96%)]  Loss:  2.151601 (1.5937)  Time: 0.434s,   73.66/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1850/1875 ( 99%)]  Loss:  2.227158 (1.5917)  Time: 0.438s,   73.13/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 4 [1874/1875 (100%)]  Loss:  1.220928 (1.5887)  Time: 0.586s,   54.60/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.158 (0.005)\n",
            "Test: [   0/312]  Time: 1.286 (1.286)  Loss:  0.1322 (0.1322)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.132 (0.162)  Loss:  0.0945 (0.1515)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.149)  Loss:  0.2272 (0.1626)  Acc@1: 96.8750 (98.7624)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.140 (0.145)  Loss:  0.1318 (0.1792)  Acc@1: 100.0000 (98.1995)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1890 (0.2050)  Acc@1: 96.8750 (97.3103)  Acc@5: 100.0000 (99.9378)\n",
            "Test: [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1178 (0.2139)  Acc@1: 100.0000 (97.0493)  Acc@5: 100.0000 (99.9128)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4561 (0.2125)  Acc@1: 90.6250 (97.1449)  Acc@5: 100.0000 (99.9273)\n",
            "Test: [ 312/312]  Time: 0.216 (0.140)  Loss:  0.1033 (0.2103)  Acc@1: 100.0000 (97.2100)  Acc@5: 100.0000 (99.9300)\n",
            "Test (EMA): [   0/312]  Time: 1.235 (1.235)  Loss:  0.1196 (0.1196)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.132 (0.161)  Loss:  0.0875 (0.1431)  Acc@1: 100.0000 (99.2034)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  0.2086 (0.1769)  Acc@1: 96.8750 (98.1436)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.136 (0.144)  Loss:  0.1118 (0.1914)  Acc@1: 100.0000 (97.8270)  Acc@5: 100.0000 (99.9586)\n",
            "Test (EMA): [ 200/312]  Time: 0.138 (0.142)  Loss:  0.2083 (0.2190)  Acc@1: 96.8750 (96.7662)  Acc@5: 100.0000 (99.9223)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1233 (0.2192)  Acc@1: 100.0000 (96.8003)  Acc@5: 100.0000 (99.9253)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4448 (0.2179)  Acc@1: 90.6250 (96.9165)  Acc@5: 100.0000 (99.9273)\n",
            "Test (EMA): [ 312/312]  Time: 0.216 (0.140)  Loss:  0.1254 (0.2167)  Acc@1: 100.0000 (96.9500)  Acc@5: 100.0000 (99.9300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 5 [   0/1875 (  0%)]  Loss:  2.075428 (2.0754)  Time: 2.386s,   13.41/s  (2.386s,   13.41/s)  LR: 1.000e-05  Data: 1.361 (1.361)\n",
            "Train: 5 [  50/1875 (  3%)]  Loss:  1.253926 (1.7861)  Time: 0.434s,   73.81/s  (0.475s,   67.39/s)  LR: 1.000e-05  Data: 0.004 (0.031)\n",
            "Train: 5 [ 100/1875 (  5%)]  Loss:  1.020152 (1.6459)  Time: 0.441s,   72.51/s  (0.456s,   70.25/s)  LR: 1.000e-05  Data: 0.004 (0.018)\n",
            "Train: 5 [ 150/1875 (  8%)]  Loss:  1.246976 (1.6942)  Time: 0.436s,   73.42/s  (0.449s,   71.26/s)  LR: 1.000e-05  Data: 0.004 (0.013)\n",
            "Train: 5 [ 200/1875 ( 11%)]  Loss:  1.150484 (1.7012)  Time: 0.436s,   73.37/s  (0.446s,   71.74/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 5 [ 250/1875 ( 13%)]  Loss:  1.710346 (1.6657)  Time: 0.436s,   73.44/s  (0.444s,   72.07/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 5 [ 300/1875 ( 16%)]  Loss:  1.931060 (1.6810)  Time: 0.432s,   74.09/s  (0.443s,   72.29/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 5 [ 350/1875 ( 19%)]  Loss:  2.145198 (1.6764)  Time: 0.434s,   73.68/s  (0.442s,   72.44/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 5 [ 400/1875 ( 21%)]  Loss:  2.034851 (1.6317)  Time: 0.438s,   73.00/s  (0.441s,   72.55/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 5 [ 450/1875 ( 24%)]  Loss:  2.097487 (1.6358)  Time: 0.439s,   72.85/s  (0.441s,   72.63/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 500/1875 ( 27%)]  Loss:  1.316619 (1.6385)  Time: 0.435s,   73.52/s  (0.440s,   72.70/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 550/1875 ( 29%)]  Loss:  1.022420 (1.6182)  Time: 0.437s,   73.25/s  (0.440s,   72.76/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 600/1875 ( 32%)]  Loss:  0.955465 (1.6211)  Time: 0.435s,   73.61/s  (0.440s,   72.81/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 5 [ 650/1875 ( 35%)]  Loss:  2.069439 (1.6111)  Time: 0.436s,   73.47/s  (0.439s,   72.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 700/1875 ( 37%)]  Loss:  1.281452 (1.6094)  Time: 0.435s,   73.60/s  (0.439s,   72.89/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 750/1875 ( 40%)]  Loss:  1.072160 (1.5793)  Time: 0.433s,   73.83/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 800/1875 ( 43%)]  Loss:  1.431452 (1.5956)  Time: 0.444s,   72.14/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 850/1875 ( 45%)]  Loss:  1.739956 (1.5854)  Time: 0.437s,   73.31/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 900/1875 ( 48%)]  Loss:  1.761819 (1.5847)  Time: 0.432s,   74.02/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [ 950/1875 ( 51%)]  Loss:  1.074483 (1.5885)  Time: 0.434s,   73.72/s  (0.438s,   73.00/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1000/1875 ( 53%)]  Loss:  0.982385 (1.5868)  Time: 0.436s,   73.36/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1050/1875 ( 56%)]  Loss:  2.143538 (1.5752)  Time: 0.440s,   72.68/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1100/1875 ( 59%)]  Loss:  0.873183 (1.5773)  Time: 0.436s,   73.37/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1150/1875 ( 61%)]  Loss:  1.580334 (1.5856)  Time: 0.443s,   72.24/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 5 [1200/1875 ( 64%)]  Loss:  1.070212 (1.5931)  Time: 0.435s,   73.61/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1250/1875 ( 67%)]  Loss:  1.684857 (1.5845)  Time: 0.437s,   73.20/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1300/1875 ( 69%)]  Loss:  1.032535 (1.5783)  Time: 0.436s,   73.47/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1350/1875 ( 72%)]  Loss:  2.155602 (1.5890)  Time: 0.435s,   73.59/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1400/1875 ( 75%)]  Loss:  1.308266 (1.5893)  Time: 0.436s,   73.48/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1450/1875 ( 77%)]  Loss:  1.855048 (1.5804)  Time: 0.435s,   73.57/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1500/1875 ( 80%)]  Loss:  0.863452 (1.5801)  Time: 0.440s,   72.77/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1550/1875 ( 83%)]  Loss:  1.163501 (1.5760)  Time: 0.438s,   73.08/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1600/1875 ( 85%)]  Loss:  2.273272 (1.5799)  Time: 0.436s,   73.33/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1650/1875 ( 88%)]  Loss:  1.687756 (1.5792)  Time: 0.434s,   73.68/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1700/1875 ( 91%)]  Loss:  2.102413 (1.5794)  Time: 0.435s,   73.51/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1750/1875 ( 93%)]  Loss:  2.047903 (1.5894)  Time: 0.433s,   73.85/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1800/1875 ( 96%)]  Loss:  2.052733 (1.5888)  Time: 0.434s,   73.69/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1850/1875 ( 99%)]  Loss:  2.181231 (1.5860)  Time: 0.444s,   72.12/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 5 [1874/1875 (100%)]  Loss:  1.133331 (1.5824)  Time: 0.580s,   55.17/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.154 (0.005)\n",
            "Test: [   0/312]  Time: 1.306 (1.306)  Loss:  0.1460 (0.1460)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.137 (0.162)  Loss:  0.0874 (0.1578)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.137 (0.149)  Loss:  0.2094 (0.1654)  Acc@1: 96.8750 (98.6077)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.140 (0.144)  Loss:  0.1293 (0.1785)  Acc@1: 100.0000 (98.3030)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2546 (0.2041)  Acc@1: 96.8750 (97.2948)  Acc@5: 100.0000 (99.9067)\n",
            "Test: [ 250/312]  Time: 0.132 (0.140)  Loss:  0.1147 (0.2086)  Acc@1: 100.0000 (97.1738)  Acc@5: 100.0000 (99.9128)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.3501 (0.2045)  Acc@1: 90.6250 (97.3422)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 312/312]  Time: 0.221 (0.140)  Loss:  0.0978 (0.2024)  Acc@1: 100.0000 (97.4100)  Acc@5: 100.0000 (99.9200)\n",
            "Test (EMA): [   0/312]  Time: 1.201 (1.201)  Loss:  0.1179 (0.1179)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.140 (0.161)  Loss:  0.0867 (0.1408)  Acc@1: 100.0000 (99.2034)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  0.2041 (0.1738)  Acc@1: 96.8750 (98.1126)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.151 (0.144)  Loss:  0.1119 (0.1879)  Acc@1: 100.0000 (97.8477)  Acc@5: 100.0000 (99.9586)\n",
            "Test (EMA): [ 200/312]  Time: 0.139 (0.142)  Loss:  0.2067 (0.2150)  Acc@1: 96.8750 (96.8595)  Acc@5: 100.0000 (99.9223)\n",
            "Test (EMA): [ 250/312]  Time: 0.132 (0.141)  Loss:  0.1217 (0.2158)  Acc@1: 100.0000 (96.8501)  Acc@5: 100.0000 (99.9253)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4382 (0.2148)  Acc@1: 90.6250 (96.9581)  Acc@5: 100.0000 (99.9273)\n",
            "Test (EMA): [ 312/312]  Time: 0.225 (0.140)  Loss:  0.1218 (0.2136)  Acc@1: 100.0000 (96.9900)  Acc@5: 100.0000 (99.9300)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 6 [   0/1875 (  0%)]  Loss:  2.084257 (2.0843)  Time: 2.432s,   13.16/s  (2.432s,   13.16/s)  LR: 1.000e-05  Data: 1.471 (1.471)\n",
            "Train: 6 [  50/1875 (  3%)]  Loss:  1.320088 (1.8098)  Time: 0.438s,   73.06/s  (0.477s,   67.13/s)  LR: 1.000e-05  Data: 0.004 (0.034)\n",
            "Train: 6 [ 100/1875 (  5%)]  Loss:  1.298859 (1.6472)  Time: 0.435s,   73.48/s  (0.457s,   70.06/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 6 [ 150/1875 (  8%)]  Loss:  1.185557 (1.6988)  Time: 0.438s,   73.12/s  (0.450s,   71.15/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 6 [ 200/1875 ( 11%)]  Loss:  1.489531 (1.7040)  Time: 0.433s,   73.83/s  (0.446s,   71.67/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 6 [ 250/1875 ( 13%)]  Loss:  1.973575 (1.6718)  Time: 0.433s,   73.86/s  (0.445s,   71.99/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 6 [ 300/1875 ( 16%)]  Loss:  1.792620 (1.6777)  Time: 0.432s,   74.00/s  (0.443s,   72.21/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 6 [ 350/1875 ( 19%)]  Loss:  2.111567 (1.6756)  Time: 0.436s,   73.42/s  (0.442s,   72.35/s)  LR: 1.000e-05  Data: 0.005 (0.009)\n",
            "Train: 6 [ 400/1875 ( 21%)]  Loss:  2.171386 (1.6300)  Time: 0.439s,   72.90/s  (0.442s,   72.47/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 6 [ 450/1875 ( 24%)]  Loss:  2.103955 (1.6298)  Time: 0.433s,   73.85/s  (0.441s,   72.56/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 6 [ 500/1875 ( 27%)]  Loss:  1.352026 (1.6294)  Time: 0.435s,   73.59/s  (0.441s,   72.64/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 550/1875 ( 29%)]  Loss:  1.125703 (1.6048)  Time: 0.437s,   73.27/s  (0.440s,   72.71/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 600/1875 ( 32%)]  Loss:  1.403751 (1.6087)  Time: 0.435s,   73.60/s  (0.440s,   72.79/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 650/1875 ( 35%)]  Loss:  2.069832 (1.6002)  Time: 0.432s,   74.16/s  (0.439s,   72.85/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 6 [ 700/1875 ( 37%)]  Loss:  1.116544 (1.6001)  Time: 0.436s,   73.41/s  (0.439s,   72.91/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 750/1875 ( 40%)]  Loss:  1.062867 (1.5675)  Time: 0.435s,   73.63/s  (0.439s,   72.96/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 800/1875 ( 43%)]  Loss:  1.449601 (1.5821)  Time: 0.435s,   73.60/s  (0.438s,   72.99/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 850/1875 ( 45%)]  Loss:  1.676620 (1.5694)  Time: 0.436s,   73.46/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 900/1875 ( 48%)]  Loss:  1.752029 (1.5688)  Time: 0.435s,   73.62/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [ 950/1875 ( 51%)]  Loss:  1.186393 (1.5763)  Time: 0.437s,   73.22/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1000/1875 ( 53%)]  Loss:  0.963591 (1.5724)  Time: 0.433s,   73.94/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1050/1875 ( 56%)]  Loss:  2.261300 (1.5629)  Time: 0.438s,   73.13/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1100/1875 ( 59%)]  Loss:  0.949469 (1.5643)  Time: 0.435s,   73.49/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 6 [1150/1875 ( 61%)]  Loss:  1.743989 (1.5715)  Time: 0.436s,   73.35/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1200/1875 ( 64%)]  Loss:  1.209848 (1.5772)  Time: 0.435s,   73.52/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1250/1875 ( 67%)]  Loss:  1.338786 (1.5692)  Time: 0.436s,   73.48/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 6 [1300/1875 ( 69%)]  Loss:  0.982703 (1.5636)  Time: 0.438s,   73.11/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1350/1875 ( 72%)]  Loss:  1.928543 (1.5753)  Time: 0.435s,   73.57/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1400/1875 ( 75%)]  Loss:  0.834268 (1.5757)  Time: 0.434s,   73.77/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1450/1875 ( 77%)]  Loss:  1.952189 (1.5676)  Time: 0.437s,   73.28/s  (0.437s,   73.16/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1500/1875 ( 80%)]  Loss:  1.151173 (1.5668)  Time: 0.435s,   73.51/s  (0.437s,   73.17/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1550/1875 ( 83%)]  Loss:  1.343191 (1.5630)  Time: 0.435s,   73.65/s  (0.437s,   73.18/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1600/1875 ( 85%)]  Loss:  1.920195 (1.5671)  Time: 0.436s,   73.42/s  (0.437s,   73.18/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1650/1875 ( 88%)]  Loss:  1.445459 (1.5662)  Time: 0.443s,   72.24/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1700/1875 ( 91%)]  Loss:  2.272107 (1.5669)  Time: 0.435s,   73.63/s  (0.437s,   73.19/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1750/1875 ( 93%)]  Loss:  2.122797 (1.5767)  Time: 0.437s,   73.28/s  (0.437s,   73.20/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1800/1875 ( 96%)]  Loss:  2.097280 (1.5764)  Time: 0.439s,   72.97/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1850/1875 ( 99%)]  Loss:  2.146214 (1.5741)  Time: 0.434s,   73.70/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 6 [1874/1875 (100%)]  Loss:  1.035027 (1.5710)  Time: 0.581s,   55.03/s  (0.437s,   73.21/s)  LR: 1.000e-05  Data: 0.155 (0.005)\n",
            "Test: [   0/312]  Time: 1.271 (1.271)  Loss:  0.1187 (0.1187)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.133 (0.162)  Loss:  0.0826 (0.1362)  Acc@1: 100.0000 (99.2034)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.138 (0.149)  Loss:  0.2058 (0.1500)  Acc@1: 96.8750 (98.6386)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.138 (0.145)  Loss:  0.1351 (0.1710)  Acc@1: 100.0000 (98.2202)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.138 (0.143)  Loss:  0.1752 (0.1903)  Acc@1: 100.0000 (97.4347)  Acc@5: 100.0000 (99.9689)\n",
            "Test: [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1149 (0.1921)  Acc@1: 100.0000 (97.4228)  Acc@5: 100.0000 (99.9751)\n",
            "Test: [ 300/312]  Time: 0.131 (0.140)  Loss:  0.4165 (0.1945)  Acc@1: 90.6250 (97.5291)  Acc@5: 100.0000 (99.9689)\n",
            "Test: [ 312/312]  Time: 0.219 (0.140)  Loss:  0.1055 (0.1932)  Acc@1: 100.0000 (97.5800)  Acc@5: 100.0000 (99.9700)\n",
            "Test (EMA): [   0/312]  Time: 1.077 (1.077)  Loss:  0.1167 (0.1167)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.138 (0.163)  Loss:  0.0858 (0.1387)  Acc@1: 100.0000 (99.2034)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.141 (0.150)  Loss:  0.2006 (0.1707)  Acc@1: 96.8750 (98.2054)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.139 (0.145)  Loss:  0.1119 (0.1845)  Acc@1: 100.0000 (97.9305)  Acc@5: 100.0000 (99.9793)\n",
            "Test (EMA): [ 200/312]  Time: 0.140 (0.143)  Loss:  0.2056 (0.2108)  Acc@1: 96.8750 (96.9994)  Acc@5: 100.0000 (99.9378)\n",
            "Test (EMA): [ 250/312]  Time: 0.132 (0.141)  Loss:  0.1199 (0.2123)  Acc@1: 100.0000 (96.9746)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4302 (0.2116)  Acc@1: 90.6250 (97.0723)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 312/312]  Time: 0.217 (0.140)  Loss:  0.1192 (0.2103)  Acc@1: 100.0000 (97.1000)  Acc@5: 100.0000 (99.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-6.pth.tar', 97.1)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 7 [   0/1875 (  0%)]  Loss:  1.981256 (1.9813)  Time: 2.457s,   13.03/s  (2.457s,   13.03/s)  LR: 1.000e-05  Data: 1.606 (1.606)\n",
            "Train: 7 [  50/1875 (  3%)]  Loss:  1.172406 (1.7800)  Time: 0.435s,   73.50/s  (0.477s,   67.02/s)  LR: 1.000e-05  Data: 0.004 (0.036)\n",
            "Train: 7 [ 100/1875 (  5%)]  Loss:  1.113936 (1.6326)  Time: 0.437s,   73.27/s  (0.457s,   70.02/s)  LR: 1.000e-05  Data: 0.004 (0.020)\n",
            "Train: 7 [ 150/1875 (  8%)]  Loss:  1.127778 (1.6783)  Time: 0.439s,   72.91/s  (0.450s,   71.07/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 7 [ 200/1875 ( 11%)]  Loss:  1.376925 (1.6832)  Time: 0.439s,   72.84/s  (0.447s,   71.60/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 7 [ 250/1875 ( 13%)]  Loss:  1.968096 (1.6486)  Time: 0.437s,   73.23/s  (0.445s,   71.95/s)  LR: 1.000e-05  Data: 0.004 (0.011)\n",
            "Train: 7 [ 300/1875 ( 16%)]  Loss:  2.017708 (1.6596)  Time: 0.439s,   72.88/s  (0.443s,   72.17/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 7 [ 350/1875 ( 19%)]  Loss:  1.873287 (1.6571)  Time: 0.433s,   73.90/s  (0.442s,   72.33/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 7 [ 400/1875 ( 21%)]  Loss:  1.932256 (1.6140)  Time: 0.435s,   73.58/s  (0.442s,   72.45/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 450/1875 ( 24%)]  Loss:  1.970210 (1.6135)  Time: 0.436s,   73.33/s  (0.441s,   72.54/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 500/1875 ( 27%)]  Loss:  1.159149 (1.6146)  Time: 0.438s,   72.99/s  (0.441s,   72.61/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 7 [ 550/1875 ( 29%)]  Loss:  0.960514 (1.5961)  Time: 0.431s,   74.25/s  (0.440s,   72.69/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 600/1875 ( 32%)]  Loss:  1.254551 (1.6003)  Time: 0.434s,   73.78/s  (0.440s,   72.75/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 650/1875 ( 35%)]  Loss:  1.868312 (1.5930)  Time: 0.445s,   71.95/s  (0.440s,   72.78/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 7 [ 700/1875 ( 37%)]  Loss:  1.274156 (1.5911)  Time: 0.438s,   73.11/s  (0.439s,   72.82/s)  LR: 1.000e-05  Data: 0.005 (0.007)\n",
            "Train: 7 [ 750/1875 ( 40%)]  Loss:  1.056222 (1.5575)  Time: 0.435s,   73.49/s  (0.439s,   72.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 800/1875 ( 43%)]  Loss:  1.371154 (1.5715)  Time: 0.443s,   72.31/s  (0.439s,   72.88/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 850/1875 ( 45%)]  Loss:  1.657921 (1.5607)  Time: 0.436s,   73.36/s  (0.439s,   72.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 900/1875 ( 48%)]  Loss:  1.786451 (1.5603)  Time: 0.435s,   73.61/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [ 950/1875 ( 51%)]  Loss:  1.065001 (1.5649)  Time: 0.436s,   73.39/s  (0.439s,   72.95/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1000/1875 ( 53%)]  Loss:  1.150831 (1.5652)  Time: 0.445s,   71.94/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1050/1875 ( 56%)]  Loss:  1.927685 (1.5556)  Time: 0.435s,   73.48/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1100/1875 ( 59%)]  Loss:  0.900207 (1.5573)  Time: 0.436s,   73.47/s  (0.438s,   73.00/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1150/1875 ( 61%)]  Loss:  1.724097 (1.5656)  Time: 0.438s,   73.03/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1200/1875 ( 64%)]  Loss:  1.486535 (1.5724)  Time: 0.436s,   73.36/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1250/1875 ( 67%)]  Loss:  1.564591 (1.5640)  Time: 0.435s,   73.49/s  (0.438s,   73.04/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1300/1875 ( 69%)]  Loss:  0.995644 (1.5572)  Time: 0.437s,   73.15/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 7 [1350/1875 ( 72%)]  Loss:  2.215622 (1.5685)  Time: 0.445s,   71.92/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 7 [1400/1875 ( 75%)]  Loss:  1.208561 (1.5692)  Time: 0.434s,   73.77/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 7 [1450/1875 ( 77%)]  Loss:  2.132348 (1.5603)  Time: 0.435s,   73.58/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 7 [1500/1875 ( 80%)]  Loss:  0.975496 (1.5589)  Time: 0.436s,   73.40/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1550/1875 ( 83%)]  Loss:  1.325751 (1.5541)  Time: 0.435s,   73.60/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1600/1875 ( 85%)]  Loss:  2.063261 (1.5584)  Time: 0.442s,   72.36/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1650/1875 ( 88%)]  Loss:  1.484006 (1.5576)  Time: 0.436s,   73.39/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1700/1875 ( 91%)]  Loss:  2.164546 (1.5575)  Time: 0.436s,   73.46/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1750/1875 ( 93%)]  Loss:  2.056590 (1.5678)  Time: 0.435s,   73.49/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1800/1875 ( 96%)]  Loss:  2.018200 (1.5673)  Time: 0.444s,   72.00/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.014 (0.005)\n",
            "Train: 7 [1850/1875 ( 99%)]  Loss:  2.222600 (1.5647)  Time: 0.437s,   73.29/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 7 [1874/1875 (100%)]  Loss:  1.157904 (1.5614)  Time: 0.597s,   53.58/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.172 (0.005)\n",
            "Test: [   0/312]  Time: 1.194 (1.194)  Loss:  0.1165 (0.1165)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.160)  Loss:  0.0978 (0.1476)  Acc@1: 100.0000 (98.7745)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.148)  Loss:  0.1776 (0.1653)  Acc@1: 96.8750 (98.1745)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.132 (0.144)  Loss:  0.1199 (0.1705)  Acc@1: 100.0000 (98.1167)  Acc@5: 100.0000 (99.9586)\n",
            "Test: [ 200/312]  Time: 0.138 (0.142)  Loss:  0.1450 (0.1872)  Acc@1: 100.0000 (97.4658)  Acc@5: 100.0000 (99.9689)\n",
            "Test: [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1204 (0.1869)  Acc@1: 100.0000 (97.5349)  Acc@5: 100.0000 (99.9751)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.3877 (0.1890)  Acc@1: 90.6250 (97.5914)  Acc@5: 100.0000 (99.9585)\n",
            "Test: [ 312/312]  Time: 0.216 (0.140)  Loss:  0.1002 (0.1872)  Acc@1: 100.0000 (97.6500)  Acc@5: 100.0000 (99.9600)\n",
            "Test (EMA): [   0/312]  Time: 1.209 (1.209)  Loss:  0.1153 (0.1153)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.134 (0.162)  Loss:  0.0851 (0.1368)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.140 (0.149)  Loss:  0.1964 (0.1682)  Acc@1: 96.8750 (98.2983)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.145)  Loss:  0.1123 (0.1814)  Acc@1: 100.0000 (98.0339)  Acc@5: 100.0000 (99.9793)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  0.2036 (0.2073)  Acc@1: 96.8750 (97.1238)  Acc@5: 100.0000 (99.9378)\n",
            "Test (EMA): [ 250/312]  Time: 0.142 (0.141)  Loss:  0.1180 (0.2090)  Acc@1: 100.0000 (97.0742)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4229 (0.2085)  Acc@1: 90.6250 (97.1553)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 312/312]  Time: 0.219 (0.140)  Loss:  0.1161 (0.2073)  Acc@1: 100.0000 (97.1900)  Acc@5: 100.0000 (99.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-7.pth.tar', 97.19)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-6.pth.tar', 97.1)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 8 [   0/1875 (  0%)]  Loss:  2.105181 (2.1052)  Time: 2.403s,   13.32/s  (2.403s,   13.32/s)  LR: 1.000e-05  Data: 1.454 (1.454)\n",
            "Train: 8 [  50/1875 (  3%)]  Loss:  1.049684 (1.7547)  Time: 0.437s,   73.21/s  (0.476s,   67.17/s)  LR: 1.000e-05  Data: 0.005 (0.034)\n",
            "Train: 8 [ 100/1875 (  5%)]  Loss:  1.253836 (1.6258)  Time: 0.435s,   73.60/s  (0.457s,   70.05/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 8 [ 150/1875 (  8%)]  Loss:  1.085627 (1.6732)  Time: 0.444s,   72.13/s  (0.450s,   71.11/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 8 [ 200/1875 ( 11%)]  Loss:  1.389692 (1.6800)  Time: 0.436s,   73.47/s  (0.447s,   71.63/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 8 [ 250/1875 ( 13%)]  Loss:  1.811236 (1.6474)  Time: 0.431s,   74.18/s  (0.445s,   71.96/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 8 [ 300/1875 ( 16%)]  Loss:  2.021513 (1.6557)  Time: 0.434s,   73.76/s  (0.443s,   72.18/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 8 [ 350/1875 ( 19%)]  Loss:  1.851396 (1.6535)  Time: 0.437s,   73.16/s  (0.442s,   72.33/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 8 [ 400/1875 ( 21%)]  Loss:  1.853379 (1.6056)  Time: 0.436s,   73.46/s  (0.442s,   72.46/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 450/1875 ( 24%)]  Loss:  2.137784 (1.6036)  Time: 0.434s,   73.80/s  (0.441s,   72.55/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 8 [ 500/1875 ( 27%)]  Loss:  1.373540 (1.6045)  Time: 0.444s,   72.14/s  (0.441s,   72.63/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 550/1875 ( 29%)]  Loss:  1.186372 (1.5838)  Time: 0.436s,   73.44/s  (0.440s,   72.69/s)  LR: 1.000e-05  Data: 0.005 (0.007)\n",
            "Train: 8 [ 600/1875 ( 32%)]  Loss:  1.146248 (1.5897)  Time: 0.436s,   73.34/s  (0.440s,   72.76/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 650/1875 ( 35%)]  Loss:  1.860222 (1.5802)  Time: 0.434s,   73.67/s  (0.439s,   72.82/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 8 [ 700/1875 ( 37%)]  Loss:  1.113053 (1.5784)  Time: 0.432s,   74.02/s  (0.439s,   72.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 750/1875 ( 40%)]  Loss:  1.201346 (1.5454)  Time: 0.434s,   73.68/s  (0.439s,   72.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 800/1875 ( 43%)]  Loss:  1.416819 (1.5604)  Time: 0.437s,   73.18/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 850/1875 ( 45%)]  Loss:  1.430633 (1.5496)  Time: 0.436s,   73.45/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 900/1875 ( 48%)]  Loss:  1.813349 (1.5507)  Time: 0.435s,   73.52/s  (0.439s,   72.96/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [ 950/1875 ( 51%)]  Loss:  0.732238 (1.5574)  Time: 0.434s,   73.67/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1000/1875 ( 53%)]  Loss:  1.127991 (1.5567)  Time: 0.444s,   72.00/s  (0.438s,   72.99/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1050/1875 ( 56%)]  Loss:  2.005185 (1.5473)  Time: 0.433s,   73.84/s  (0.438s,   73.01/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1100/1875 ( 59%)]  Loss:  1.000076 (1.5495)  Time: 0.436s,   73.46/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 8 [1150/1875 ( 61%)]  Loss:  1.688163 (1.5573)  Time: 0.434s,   73.71/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1200/1875 ( 64%)]  Loss:  1.277440 (1.5644)  Time: 0.434s,   73.65/s  (0.438s,   73.04/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1250/1875 ( 67%)]  Loss:  1.591320 (1.5560)  Time: 0.435s,   73.61/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1300/1875 ( 69%)]  Loss:  1.218783 (1.5488)  Time: 0.438s,   73.00/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 8 [1350/1875 ( 72%)]  Loss:  2.173654 (1.5606)  Time: 0.433s,   73.90/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1400/1875 ( 75%)]  Loss:  1.110828 (1.5603)  Time: 0.434s,   73.77/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1450/1875 ( 77%)]  Loss:  1.975605 (1.5508)  Time: 0.434s,   73.72/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1500/1875 ( 80%)]  Loss:  0.782920 (1.5492)  Time: 0.436s,   73.34/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1550/1875 ( 83%)]  Loss:  0.885981 (1.5444)  Time: 0.434s,   73.77/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1600/1875 ( 85%)]  Loss:  2.118761 (1.5491)  Time: 0.444s,   72.04/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1650/1875 ( 88%)]  Loss:  1.444271 (1.5468)  Time: 0.439s,   72.97/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.007 (0.005)\n",
            "Train: 8 [1700/1875 ( 91%)]  Loss:  1.985370 (1.5455)  Time: 0.440s,   72.73/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.008 (0.005)\n",
            "Train: 8 [1750/1875 ( 93%)]  Loss:  1.939091 (1.5552)  Time: 0.436s,   73.36/s  (0.438s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1800/1875 ( 96%)]  Loss:  2.171116 (1.5545)  Time: 0.436s,   73.44/s  (0.437s,   73.14/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1850/1875 ( 99%)]  Loss:  2.152148 (1.5529)  Time: 0.435s,   73.65/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 8 [1874/1875 (100%)]  Loss:  0.905311 (1.5493)  Time: 0.589s,   54.33/s  (0.437s,   73.15/s)  LR: 1.000e-05  Data: 0.162 (0.005)\n",
            "Test: [   0/312]  Time: 1.172 (1.172)  Loss:  0.1288 (0.1288)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.139 (0.160)  Loss:  0.0832 (0.1471)  Acc@1: 100.0000 (98.8971)  Acc@5: 100.0000 (99.9387)\n",
            "Test: [ 100/312]  Time: 0.138 (0.148)  Loss:  0.2233 (0.1642)  Acc@1: 96.8750 (98.1126)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1188 (0.1806)  Acc@1: 100.0000 (97.8063)  Acc@5: 100.0000 (99.9586)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1349 (0.1879)  Acc@1: 100.0000 (97.4347)  Acc@5: 100.0000 (99.9534)\n",
            "Test: [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1087 (0.1863)  Acc@1: 100.0000 (97.4477)  Acc@5: 100.0000 (99.9626)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.3335 (0.1840)  Acc@1: 90.6250 (97.5914)  Acc@5: 100.0000 (99.9585)\n",
            "Test: [ 312/312]  Time: 0.220 (0.140)  Loss:  0.0962 (0.1820)  Acc@1: 100.0000 (97.6600)  Acc@5: 100.0000 (99.9600)\n",
            "Test (EMA): [   0/312]  Time: 1.177 (1.177)  Loss:  0.1140 (0.1140)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.160)  Loss:  0.0842 (0.1351)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.131 (0.148)  Loss:  0.1918 (0.1655)  Acc@1: 96.8750 (98.3292)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1125 (0.1782)  Acc@1: 100.0000 (98.0753)  Acc@5: 100.0000 (99.9793)\n",
            "Test (EMA): [ 200/312]  Time: 0.140 (0.142)  Loss:  0.2000 (0.2035)  Acc@1: 96.8750 (97.2015)  Acc@5: 100.0000 (99.9378)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1163 (0.2054)  Acc@1: 100.0000 (97.1738)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4187 (0.2052)  Acc@1: 90.6250 (97.2280)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 312/312]  Time: 0.226 (0.140)  Loss:  0.1133 (0.2040)  Acc@1: 100.0000 (97.2700)  Acc@5: 100.0000 (99.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-8.pth.tar', 97.27)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-7.pth.tar', 97.19)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-6.pth.tar', 97.1)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 9 [   0/1875 (  0%)]  Loss:  2.050515 (2.0505)  Time: 2.449s,   13.07/s  (2.449s,   13.07/s)  LR: 1.000e-05  Data: 1.531 (1.531)\n",
            "Train: 9 [  50/1875 (  3%)]  Loss:  1.183356 (1.8037)  Time: 0.436s,   73.32/s  (0.476s,   67.25/s)  LR: 1.000e-05  Data: 0.005 (0.035)\n",
            "Train: 9 [ 100/1875 (  5%)]  Loss:  1.086012 (1.6439)  Time: 0.436s,   73.39/s  (0.456s,   70.13/s)  LR: 1.000e-05  Data: 0.004 (0.020)\n",
            "Train: 9 [ 150/1875 (  8%)]  Loss:  1.126000 (1.6854)  Time: 0.434s,   73.70/s  (0.450s,   71.15/s)  LR: 1.000e-05  Data: 0.004 (0.015)\n",
            "Train: 9 [ 200/1875 ( 11%)]  Loss:  1.361113 (1.6934)  Time: 0.434s,   73.67/s  (0.447s,   71.65/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 9 [ 250/1875 ( 13%)]  Loss:  1.851372 (1.6570)  Time: 0.435s,   73.63/s  (0.445s,   71.98/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 9 [ 300/1875 ( 16%)]  Loss:  2.112857 (1.6631)  Time: 0.441s,   72.62/s  (0.443s,   72.23/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 9 [ 350/1875 ( 19%)]  Loss:  1.952902 (1.6577)  Time: 0.437s,   73.27/s  (0.442s,   72.40/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 9 [ 400/1875 ( 21%)]  Loss:  2.020745 (1.6127)  Time: 0.437s,   73.17/s  (0.441s,   72.49/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 9 [ 450/1875 ( 24%)]  Loss:  1.882124 (1.6093)  Time: 0.436s,   73.41/s  (0.441s,   72.60/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 9 [ 500/1875 ( 27%)]  Loss:  1.274465 (1.6080)  Time: 0.433s,   73.88/s  (0.440s,   72.70/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 550/1875 ( 29%)]  Loss:  0.970845 (1.5840)  Time: 0.442s,   72.41/s  (0.440s,   72.75/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 600/1875 ( 32%)]  Loss:  1.183555 (1.5862)  Time: 0.437s,   73.29/s  (0.440s,   72.80/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 650/1875 ( 35%)]  Loss:  2.097466 (1.5748)  Time: 0.437s,   73.29/s  (0.439s,   72.83/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 700/1875 ( 37%)]  Loss:  1.407232 (1.5727)  Time: 0.435s,   73.57/s  (0.439s,   72.87/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 9 [ 750/1875 ( 40%)]  Loss:  1.067323 (1.5409)  Time: 0.439s,   72.95/s  (0.439s,   72.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 800/1875 ( 43%)]  Loss:  1.772330 (1.5561)  Time: 0.436s,   73.43/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 9 [ 850/1875 ( 45%)]  Loss:  1.651894 (1.5456)  Time: 0.437s,   73.15/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 9 [ 900/1875 ( 48%)]  Loss:  1.973458 (1.5454)  Time: 0.443s,   72.16/s  (0.439s,   72.96/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [ 950/1875 ( 51%)]  Loss:  0.936372 (1.5516)  Time: 0.435s,   73.54/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1000/1875 ( 53%)]  Loss:  1.046607 (1.5499)  Time: 0.437s,   73.23/s  (0.438s,   72.99/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 9 [1050/1875 ( 56%)]  Loss:  1.946406 (1.5399)  Time: 0.435s,   73.55/s  (0.438s,   73.01/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1100/1875 ( 59%)]  Loss:  1.018283 (1.5411)  Time: 0.434s,   73.66/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1150/1875 ( 61%)]  Loss:  1.887571 (1.5495)  Time: 0.437s,   73.17/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 9 [1200/1875 ( 64%)]  Loss:  1.230586 (1.5567)  Time: 0.437s,   73.23/s  (0.438s,   73.04/s)  LR: 1.000e-05  Data: 0.005 (0.006)\n",
            "Train: 9 [1250/1875 ( 67%)]  Loss:  1.521923 (1.5479)  Time: 0.446s,   71.74/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1300/1875 ( 69%)]  Loss:  1.192099 (1.5421)  Time: 0.434s,   73.79/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1350/1875 ( 72%)]  Loss:  2.043748 (1.5543)  Time: 0.436s,   73.44/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 9 [1400/1875 ( 75%)]  Loss:  0.998829 (1.5547)  Time: 0.436s,   73.39/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1450/1875 ( 77%)]  Loss:  2.050835 (1.5445)  Time: 0.437s,   73.21/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 9 [1500/1875 ( 80%)]  Loss:  0.848598 (1.5438)  Time: 0.436s,   73.42/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1550/1875 ( 83%)]  Loss:  1.348109 (1.5394)  Time: 0.433s,   73.84/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1600/1875 ( 85%)]  Loss:  1.977609 (1.5438)  Time: 0.437s,   73.19/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1650/1875 ( 88%)]  Loss:  1.587802 (1.5427)  Time: 0.434s,   73.71/s  (0.438s,   73.11/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1700/1875 ( 91%)]  Loss:  1.961529 (1.5425)  Time: 0.435s,   73.60/s  (0.438s,   73.12/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1750/1875 ( 93%)]  Loss:  2.060817 (1.5533)  Time: 0.437s,   73.28/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1800/1875 ( 96%)]  Loss:  1.838915 (1.5536)  Time: 0.435s,   73.54/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1850/1875 ( 99%)]  Loss:  1.994374 (1.5515)  Time: 0.435s,   73.64/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 9 [1874/1875 (100%)]  Loss:  1.074273 (1.5483)  Time: 0.590s,   54.24/s  (0.438s,   73.13/s)  LR: 1.000e-05  Data: 0.165 (0.005)\n",
            "Test: [   0/312]  Time: 1.126 (1.126)  Loss:  0.1044 (0.1044)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.133 (0.162)  Loss:  0.1050 (0.1369)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.132 (0.149)  Loss:  0.1592 (0.1486)  Acc@1: 100.0000 (98.8243)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/312]  Time: 0.138 (0.144)  Loss:  0.1423 (0.1630)  Acc@1: 100.0000 (98.5927)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1694 (0.1783)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.9534)\n",
            "Test: [ 250/312]  Time: 0.136 (0.141)  Loss:  0.1201 (0.1797)  Acc@1: 100.0000 (97.9208)  Acc@5: 100.0000 (99.9626)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.3176 (0.1808)  Acc@1: 90.6250 (97.9859)  Acc@5: 100.0000 (99.9585)\n",
            "Test: [ 312/312]  Time: 0.218 (0.140)  Loss:  0.0957 (0.1790)  Acc@1: 100.0000 (98.0300)  Acc@5: 100.0000 (99.9600)\n",
            "Test (EMA): [   0/312]  Time: 1.227 (1.227)  Loss:  0.1126 (0.1126)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.131 (0.162)  Loss:  0.0834 (0.1334)  Acc@1: 100.0000 (99.3260)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.143 (0.149)  Loss:  0.1899 (0.1627)  Acc@1: 96.8750 (98.3601)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.133 (0.144)  Loss:  0.1125 (0.1755)  Acc@1: 100.0000 (98.1167)  Acc@5: 100.0000 (99.9793)\n",
            "Test (EMA): [ 200/312]  Time: 0.139 (0.142)  Loss:  0.1959 (0.1994)  Acc@1: 96.8750 (97.3259)  Acc@5: 100.0000 (99.9378)\n",
            "Test (EMA): [ 250/312]  Time: 0.131 (0.141)  Loss:  0.1148 (0.2016)  Acc@1: 100.0000 (97.3108)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4141 (0.2017)  Acc@1: 90.6250 (97.3526)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 312/312]  Time: 0.221 (0.140)  Loss:  0.1116 (0.2005)  Acc@1: 100.0000 (97.3900)  Acc@5: 100.0000 (99.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-9.pth.tar', 97.39)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-8.pth.tar', 97.27)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-7.pth.tar', 97.19)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-6.pth.tar', 97.1)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-2.pth.tar', 96.74)\n",
            "\n",
            "Train: 10 [   0/1875 (  0%)]  Loss:  2.071095 (2.0711)  Time: 2.432s,   13.16/s  (2.432s,   13.16/s)  LR: 1.000e-05  Data: 1.506 (1.506)\n",
            "Train: 10 [  50/1875 (  3%)]  Loss:  1.053505 (1.7949)  Time: 0.434s,   73.79/s  (0.478s,   67.01/s)  LR: 1.000e-05  Data: 0.004 (0.034)\n",
            "Train: 10 [ 100/1875 (  5%)]  Loss:  1.504878 (1.6401)  Time: 0.437s,   73.31/s  (0.458s,   69.93/s)  LR: 1.000e-05  Data: 0.004 (0.019)\n",
            "Train: 10 [ 150/1875 (  8%)]  Loss:  1.111198 (1.6788)  Time: 0.445s,   71.96/s  (0.451s,   71.02/s)  LR: 1.000e-05  Data: 0.004 (0.014)\n",
            "Train: 10 [ 200/1875 ( 11%)]  Loss:  1.654292 (1.6791)  Time: 0.434s,   73.67/s  (0.447s,   71.54/s)  LR: 1.000e-05  Data: 0.004 (0.012)\n",
            "Train: 10 [ 250/1875 ( 13%)]  Loss:  1.782977 (1.6417)  Time: 0.434s,   73.66/s  (0.445s,   71.89/s)  LR: 1.000e-05  Data: 0.004 (0.010)\n",
            "Train: 10 [ 300/1875 ( 16%)]  Loss:  2.069895 (1.6427)  Time: 0.435s,   73.63/s  (0.444s,   72.12/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 10 [ 350/1875 ( 19%)]  Loss:  1.926164 (1.6407)  Time: 0.434s,   73.69/s  (0.442s,   72.32/s)  LR: 1.000e-05  Data: 0.004 (0.009)\n",
            "Train: 10 [ 400/1875 ( 21%)]  Loss:  1.957575 (1.5918)  Time: 0.432s,   74.04/s  (0.442s,   72.43/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 10 [ 450/1875 ( 24%)]  Loss:  1.845872 (1.5918)  Time: 0.436s,   73.41/s  (0.441s,   72.54/s)  LR: 1.000e-05  Data: 0.004 (0.008)\n",
            "Train: 10 [ 500/1875 ( 27%)]  Loss:  1.252828 (1.5922)  Time: 0.436s,   73.43/s  (0.441s,   72.64/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 550/1875 ( 29%)]  Loss:  0.955419 (1.5700)  Time: 0.436s,   73.34/s  (0.440s,   72.70/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 600/1875 ( 32%)]  Loss:  1.024989 (1.5756)  Time: 0.435s,   73.65/s  (0.440s,   72.75/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 650/1875 ( 35%)]  Loss:  2.003861 (1.5660)  Time: 0.442s,   72.46/s  (0.440s,   72.79/s)  LR: 1.000e-05  Data: 0.004 (0.007)\n",
            "Train: 10 [ 700/1875 ( 37%)]  Loss:  1.185586 (1.5648)  Time: 0.437s,   73.31/s  (0.439s,   72.82/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 750/1875 ( 40%)]  Loss:  0.942552 (1.5330)  Time: 0.435s,   73.63/s  (0.439s,   72.85/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 800/1875 ( 43%)]  Loss:  1.556445 (1.5508)  Time: 0.436s,   73.41/s  (0.439s,   72.87/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 850/1875 ( 45%)]  Loss:  1.642313 (1.5403)  Time: 0.434s,   73.77/s  (0.439s,   72.90/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 900/1875 ( 48%)]  Loss:  1.843025 (1.5397)  Time: 0.433s,   73.94/s  (0.439s,   72.92/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [ 950/1875 ( 51%)]  Loss:  0.955277 (1.5459)  Time: 0.435s,   73.57/s  (0.439s,   72.94/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1000/1875 ( 53%)]  Loss:  0.884871 (1.5436)  Time: 0.444s,   72.14/s  (0.439s,   72.95/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1050/1875 ( 56%)]  Loss:  1.953424 (1.5319)  Time: 0.437s,   73.30/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1100/1875 ( 59%)]  Loss:  1.065271 (1.5340)  Time: 0.435s,   73.49/s  (0.438s,   72.98/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1150/1875 ( 61%)]  Loss:  1.570473 (1.5431)  Time: 0.434s,   73.72/s  (0.438s,   72.99/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1200/1875 ( 64%)]  Loss:  1.294112 (1.5513)  Time: 0.434s,   73.78/s  (0.438s,   73.01/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1250/1875 ( 67%)]  Loss:  1.583857 (1.5423)  Time: 0.434s,   73.77/s  (0.438s,   73.02/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1300/1875 ( 69%)]  Loss:  0.901830 (1.5360)  Time: 0.435s,   73.63/s  (0.438s,   73.03/s)  LR: 1.000e-05  Data: 0.004 (0.006)\n",
            "Train: 10 [1350/1875 ( 72%)]  Loss:  1.896775 (1.5486)  Time: 0.443s,   72.16/s  (0.438s,   73.04/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1400/1875 ( 75%)]  Loss:  1.071848 (1.5493)  Time: 0.435s,   73.54/s  (0.438s,   73.05/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1450/1875 ( 77%)]  Loss:  1.950855 (1.5417)  Time: 0.436s,   73.42/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.005 (0.005)\n",
            "Train: 10 [1500/1875 ( 80%)]  Loss:  0.956284 (1.5403)  Time: 0.435s,   73.65/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1550/1875 ( 83%)]  Loss:  1.258420 (1.5354)  Time: 0.433s,   73.90/s  (0.438s,   73.07/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1600/1875 ( 85%)]  Loss:  2.112185 (1.5394)  Time: 0.436s,   73.33/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1650/1875 ( 88%)]  Loss:  1.452432 (1.5377)  Time: 0.433s,   73.85/s  (0.438s,   73.08/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1700/1875 ( 91%)]  Loss:  2.267354 (1.5385)  Time: 0.443s,   72.28/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1750/1875 ( 93%)]  Loss:  2.068848 (1.5489)  Time: 0.435s,   73.53/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1800/1875 ( 96%)]  Loss:  2.138302 (1.5488)  Time: 0.433s,   73.87/s  (0.438s,   73.09/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1850/1875 ( 99%)]  Loss:  2.173086 (1.5469)  Time: 0.434s,   73.78/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.004 (0.005)\n",
            "Train: 10 [1874/1875 (100%)]  Loss:  1.263708 (1.5446)  Time: 0.587s,   54.50/s  (0.438s,   73.10/s)  LR: 1.000e-05  Data: 0.158 (0.005)\n",
            "Test: [   0/312]  Time: 1.223 (1.223)  Loss:  0.1124 (0.1124)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/312]  Time: 0.131 (0.162)  Loss:  0.0988 (0.1428)  Acc@1: 100.0000 (98.8971)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/312]  Time: 0.131 (0.149)  Loss:  0.1573 (0.1700)  Acc@1: 96.8750 (97.9270)  Acc@5: 100.0000 (99.9691)\n",
            "Test: [ 150/312]  Time: 0.131 (0.144)  Loss:  0.1122 (0.1667)  Acc@1: 100.0000 (98.0960)  Acc@5: 100.0000 (99.9793)\n",
            "Test: [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1443 (0.1816)  Acc@1: 100.0000 (97.4658)  Acc@5: 100.0000 (99.9534)\n",
            "Test: [ 250/312]  Time: 0.138 (0.141)  Loss:  0.1251 (0.1834)  Acc@1: 100.0000 (97.5473)  Acc@5: 100.0000 (99.9502)\n",
            "Test: [ 300/312]  Time: 0.130 (0.140)  Loss:  0.2891 (0.1844)  Acc@1: 93.7500 (97.6225)  Acc@5: 100.0000 (99.9585)\n",
            "Test: [ 312/312]  Time: 0.218 (0.140)  Loss:  0.1132 (0.1830)  Acc@1: 100.0000 (97.6900)  Acc@5: 100.0000 (99.9600)\n",
            "Test (EMA): [   0/312]  Time: 1.263 (1.263)  Loss:  0.1110 (0.1110)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [  50/312]  Time: 0.142 (0.162)  Loss:  0.0829 (0.1315)  Acc@1: 100.0000 (99.3260)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 100/312]  Time: 0.142 (0.148)  Loss:  0.1865 (0.1600)  Acc@1: 96.8750 (98.3601)  Acc@5: 100.0000 (100.0000)\n",
            "Test (EMA): [ 150/312]  Time: 0.140 (0.144)  Loss:  0.1125 (0.1726)  Acc@1: 100.0000 (98.1374)  Acc@5: 100.0000 (99.9793)\n",
            "Test (EMA): [ 200/312]  Time: 0.131 (0.142)  Loss:  0.1920 (0.1957)  Acc@1: 96.8750 (97.3259)  Acc@5: 100.0000 (99.9378)\n",
            "Test (EMA): [ 250/312]  Time: 0.139 (0.141)  Loss:  0.1140 (0.1981)  Acc@1: 100.0000 (97.3232)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 300/312]  Time: 0.130 (0.140)  Loss:  0.4111 (0.1986)  Acc@1: 90.6250 (97.3526)  Acc@5: 100.0000 (99.9377)\n",
            "Test (EMA): [ 312/312]  Time: 0.237 (0.140)  Loss:  0.1099 (0.1974)  Acc@1: 100.0000 (97.3900)  Acc@5: 100.0000 (99.9400)\n",
            "Current checkpoints:\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-9.pth.tar', 97.39)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-10.pth.tar', 97.39)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-8.pth.tar', 97.27)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-7.pth.tar', 97.19)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-6.pth.tar', 97.1)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-5.pth.tar', 96.99)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-4.pth.tar', 96.95)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-3.pth.tar', 96.86)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-1.pth.tar', 96.76)\n",
            " ('./output/train/20210204-082514-T2t_vit_t_14-224/checkpoint-0.pth.tar', 96.75)\n",
            "\n",
            "*** Best metric: 97.39 (epoch 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUWG9C8Dwf_J"
      },
      "source": [
        "ckpt = '/content/T2T-ViT/output/train/20210204-082514-T2t_vit_t_14-224/model_best.pth.tar'\r\n",
        "!cp \"$ckpt\" /content/drive/MyDrive"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}
